"""
Test Vietnamese Optimization
Verify Vietnamese text processing capabilities
"""
import sys
from pathlib import Path

# Add parent directory to path
sys.path.insert(0, str(Path(__file__).parent))

from app.core.vietnamese_processor import get_vietnamese_processor, VIETNAMESE_AVAILABLE

def test_vietnamese_processor():
    """Test Vietnamese text processor"""
    
    print("="*60)
    print("üáªüá≥ Vietnamese Optimization Test")
    print("="*60)
    print()
    
    # Check if libraries available
    print(f"Vietnamese libraries available: {VIETNAMESE_AVAILABLE}")
    print()
    
    if not VIETNAMESE_AVAILABLE:
        print("‚ö†Ô∏è  Vietnamese libraries not installed!")
        print("   Install with: pip install underthesea pyvi")
        return
    
    # Create processor
    vi_processor = get_vietnamese_processor(
        use_tokenization=True,
        remove_stopwords=False
    )
    
    # Test texts
    test_texts = {
        'vietnamese': "Xin ch√†o! T√¥i l√† tr·ª£ l√Ω AI th√¥ng minh. T√¥i c√≥ th·ªÉ gi√∫p b·∫°n t√¨m ki·∫øm th√¥ng tin trong t√†i li·ªáu.",
        'english': "Hello! I am an intelligent AI assistant. I can help you search for information in documents.",
        'mixed': "H√¥m nay t√¥i h·ªçc v·ªÅ Machine Learning v√† Deep Learning r·∫•t th√∫ v·ªã."
    }
    
    for name, text in test_texts.items():
        print(f"{'='*60}")
        print(f"Test: {name.upper()}")
        print(f"{'='*60}")
        print(f"Original text:")
        print(f"  {text}")
        print()
        
        # Language detection
        lang = vi_processor.detect_language(text)
        print(f"Detected language: {lang}")
        print()
        
        # Statistics
        stats = vi_processor.get_statistics(text)
        print(f"Statistics:")
        print(f"  - Characters: {stats['characters']}")
        print(f"  - Words: {stats['words']}")
        print(f"  - Sentences: {stats['sentences']}")
        print(f"  - Vietnamese chars: {stats['vietnamese_chars']}")
        print(f"  - Vietnamese ratio: {stats['vietnamese_ratio']*100:.1f}%")
        print()
        
        # Cleaning
        cleaned = vi_processor.clean_text(text)
        print(f"Cleaned text:")
        print(f"  {cleaned}")
        print()
        
        # Tokenization
        if lang == 'vi':
            tokens = vi_processor.tokenize_words(text)
            print(f"Tokens (first 10):")
            print(f"  {tokens[:10]}")
            print()
            
            # Sentence segmentation
            sentences = vi_processor.segment_sentences(text)
            print(f"Sentences ({len(sentences)}):")
            for i, sent in enumerate(sentences, 1):
                print(f"  {i}. {sent}")
            print()
        
        print()
    
    # Test chunking
    print(f"{'='*60}")
    print("Test: VIETNAMESE TEXT CHUNKING")
    print(f"{'='*60}")
    
    long_text = """
    Tr√≠ tu·ªá nh√¢n t·∫°o (AI) l√† m·ªôt lƒ©nh v·ª±c nghi√™n c·ª©u khoa h·ªçc m√°y t√≠nh t·∫≠p trung v√†o vi·ªác t·∫°o ra c√°c h·ªá th·ªëng th√¥ng minh. 
    C√°c h·ªá th·ªëng n√†y c√≥ kh·∫£ nƒÉng th·ª±c hi·ªán c√°c nhi·ªám v·ª• th∆∞·ªùng ƒë√≤i h·ªèi tr√≠ tu·ªá con ng∆∞·ªùi. 
    Machine Learning l√† m·ªôt nh√°nh quan tr·ªçng c·ªßa AI, cho ph√©p m√°y t√≠nh h·ªçc t·ª´ d·ªØ li·ªáu.
    Deep Learning s·ª≠ d·ª•ng m·∫°ng neural nh√¢n t·∫°o v·ªõi nhi·ªÅu l·ªõp ƒë·ªÉ x·ª≠ l√Ω th√¥ng tin ph·ª©c t·∫°p.
    C√°c ·ª©ng d·ª•ng c·ªßa AI r·∫•t ƒëa d·∫°ng, t·ª´ nh·∫≠n di·ªán gi·ªçng n√≥i, x·ª≠ l√Ω ng√¥n ng·ªØ t·ª± nhi√™n, ƒë·∫øn xe t·ª± l√°i.
    Trong t∆∞∆°ng lai, AI s·∫Ω ng√†y c√†ng ƒë√≥ng vai tr√≤ quan tr·ªçng trong cu·ªôc s·ªëng h√†ng ng√†y c·ªßa ch√∫ng ta.
    """
    
    print(f"Original text length: {len(long_text)} characters")
    print()
    
    chunks = vi_processor.chunk_vietnamese_text(long_text, chunk_size=50, overlap=10)
    
    print(f"Number of chunks: {len(chunks)}")
    print()
    
    for i, chunk in enumerate(chunks, 1):
        word_count = len(vi_processor.tokenize_words(chunk))
        print(f"Chunk {i} ({word_count} words):")
        print(f"  {chunk[:100]}...")
        print()
    
    # Test query processing
    print(f"{'='*60}")
    print("Test: QUERY PROCESSING")
    print(f"{'='*60}")
    
    test_queries = [
        "T√¨m ki·∫øm th√¥ng tin v·ªÅ m√°y h·ªçc",
        "What is deep learning?",
        "L√†m th·∫ø n√†o ƒë·ªÉ hu·∫•n luy·ªán m√¥ h√¨nh AI?"
    ]
    
    for query in test_queries:
        print(f"Original query: {query}")
        processed = vi_processor.process_query(query, enhance=True)
        print(f"Processed query: {processed}")
        lang = vi_processor.detect_language(query)
        print(f"Language: {lang}")
        print()
    
    print("="*60)
    print("‚úÖ Vietnamese Optimization Test Complete!")
    print("="*60)


if __name__ == '__main__':
    try:
        test_vietnamese_processor()
    except Exception as e:
        print(f"‚ùå Test failed: {e}")
        import traceback
        traceback.print_exc()
