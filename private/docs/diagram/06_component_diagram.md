# 6ï¸âƒ£ COMPONENT DIAGRAM

> **Biá»ƒu Ä‘á»“ thÃ nh pháº§n há»‡ thá»‘ng AI-Assistant**  
> MÃ´ táº£ kiáº¿n trÃºc tá»•ng thá»ƒ, services, dependencies, vÃ  communication

---

## ğŸ“‹ MÃ´ táº£

Component Diagram thá»ƒ hiá»‡n:
- **Components:** 4 services + Hub Gateway + External dependencies
- **Interfaces:** RESTful APIs, WebSockets, File I/O
- **Dependencies:** Libraries, AI models, cloud services
- **Communication:** HTTP, WebSocket, gRPC (future)

---

## ğŸ¯ System Architecture Overview

```mermaid
graph TB
    subgraph Client Layer
        WebUI[ğŸŒ Web UI<br/>HTML/CSS/JS]
        MobileApp[ğŸ“± Mobile App<br/>React Native]
        API_Client[ğŸ”Œ API Clients<br/>Python/cURL]
    end
    
    subgraph API Gateway Layer
        Hub[ğŸ¯ Hub Gateway<br/>Port 3000<br/>Flask]
        Auth[ğŸ” Authentication<br/>JWT/OAuth2]
        RateLimit[âš¡ Rate Limiter<br/>Redis]
        LoadBalancer[âš–ï¸ Load Balancer<br/>Nginx]
    end
    
    subgraph Service Layer
        ChatBot[ğŸ¤– ChatBot Service<br/>Port 5001<br/>Flask + AI Models]
        Text2SQL[ğŸ“Š Text2SQL Service<br/>Port 5002<br/>Flask + Gemini]
        Speech2Text[ğŸ™ï¸ Speech2Text Service<br/>Port 7860<br/>Gradio + Models]
        StableDiff[ğŸ¨ Stable Diffusion<br/>Port 7861<br/>AUTOMATIC1111]
    end
    
    subgraph Data Layer
        PostgreSQL[(ğŸ—„ï¸ PostgreSQL<br/>Main Database)]
        MongoDB[(ğŸƒ MongoDB<br/>ChatBot Storage)]
        Redis[(âš¡ Redis<br/>Cache & Queue)]
        FileStorage[ğŸ“ File Storage<br/>Local/S3]
    end
    
    subgraph External Services
        GeminiAPI[ğŸ”· Google Gemini API]
        OpenAI_API[ğŸŸ£ OpenAI GPT-4 API]
        DeepSeek[ğŸ”µ DeepSeek API]
        HuggingFace[ğŸ¤— HuggingFace Hub]
        GoogleSearch[ğŸ” Google Search API]
        GitHubAPI[ğŸ™ GitHub API]
        ImgBB[ğŸ–¼ï¸ ImgBB Cloud Storage]
    end
    
    WebUI --> LoadBalancer
    MobileApp --> LoadBalancer
    API_Client --> LoadBalancer
    
    LoadBalancer --> Hub
    Hub --> Auth
    Hub --> RateLimit
    
    Auth --> ChatBot
    Auth --> Text2SQL
    Auth --> Speech2Text
    Auth --> StableDiff
    
    ChatBot --> PostgreSQL
    ChatBot --> MongoDB
    ChatBot --> Redis
    ChatBot --> FileStorage
    ChatBot --> GeminiAPI
    ChatBot --> OpenAI_API
    ChatBot --> DeepSeek
    ChatBot --> GoogleSearch
    ChatBot --> GitHubAPI
    ChatBot --> ImgBB
    ChatBot --> StableDiff
    
    Text2SQL --> PostgreSQL
    Text2SQL --> Redis
    Text2SQL --> GeminiAPI
    
    Speech2Text --> PostgreSQL
    Speech2Text --> FileStorage
    Speech2Text --> HuggingFace
    
    StableDiff --> FileStorage
    StableDiff --> HuggingFace
    
    style Hub fill:#6366F1,stroke:#4F46E5,color:#fff
    style ChatBot fill:#8B5CF6,stroke:#7C3AED,color:#fff
    style Text2SQL fill:#3B82F6,stroke:#2563EB,color:#fff
    style Speech2Text fill:#EF4444,stroke:#DC2626,color:#fff
    style StableDiff fill:#EC4899,stroke:#DB2777,color:#fff
```

---

## ğŸ§© Component Details

### 1. ğŸ¯ Hub Gateway Component

**Vai trÃ²:** API Gateway & Service Orchestrator

```mermaid
graph TB
    subgraph Hub Gateway
        Router[ğŸ”€ Request Router]
        ServiceRegistry[ğŸ“‹ Service Registry]
        HealthCheck[ğŸ’“ Health Monitor]
        Logger[ğŸ“ Request Logger]
        
        Router --> ServiceRegistry
        Router --> HealthCheck
        Router --> Logger
    end
    
    Clients[ğŸ‘¥ Clients] --> Router
    Router --> ChatBot[ğŸ¤– ChatBot Service]
    Router --> Text2SQL[ğŸ“Š Text2SQL Service]
    Router --> Speech2Text[ğŸ™ï¸ Speech2Text Service]
    Router --> StableDiff[ğŸ¨ Stable Diffusion]
```

**Dependencies:**
- **Framework:** Flask 3.0+
- **Routing:** Flask-RESTful
- **CORS:** Flask-CORS
- **Logging:** Python logging + File rotation

**Interfaces:**
```python
# Provided interfaces
GET  /health                    # Health check all services
POST /api/route                 # Route request to service
GET  /api/services              # List all services
GET  /api/logs                  # Get system logs

# Required interfaces
- ChatBot API: http://localhost:5001
- Text2SQL API: http://localhost:5002
- Speech2Text API: http://localhost:7860
- Stable Diffusion API: http://localhost:7861
```

**Current Implementation:**
- âœ… Basic routing
- âœ… Health check
- âš ï¸ No authentication yet
- âš ï¸ No rate limiting yet

---

### 2. ğŸ¤– ChatBot Service Component

**Vai trÃ²:** Multi-model AI conversational interface with file analysis

```mermaid
graph TB
    subgraph ChatBot Service
        API[Flask API Layer]
        Engine[ChatBot Engine]
        ModelMgr[Model Manager]
        FileMgr[File Manager]
        Memory[Memory System]
        ImageGen[Image Generator]
        SearchTool[Search Tools]
        
        API --> Engine
        Engine --> ModelMgr
        Engine --> FileMgr
        Engine --> Memory
        Engine --> ImageGen
        Engine --> SearchTool
    end
    
    API --> MongoDB[(MongoDB)]
    Memory --> MongoDB
    FileMgr --> FileStorage[(File Storage)]
    ImageGen --> StableDiff[Stable Diffusion API]
    SearchTool --> GoogleAPI[Google Search API]
    SearchTool --> GitHubAPI[GitHub API]
    ModelMgr --> GeminiAPI[Gemini API]
    ModelMgr --> OpenAI[OpenAI API]
    ModelMgr --> DeepSeek[DeepSeek API]
```

**Dependencies:**
```yaml
Core Framework:
  - Flask 3.0+
  - Flask-CORS
  - python-dotenv
  
AI Models:
  - google-generativeai (Gemini 2.0 Flash)
  - openai (GPT-4, GPT-3.5)
  - anthropic (Claude 3.5 - optional)
  
Database:
  - pymongo >= 4.6.0
  - dnspython >= 2.4.0
  
File Processing:
  - PyPDF2
  - Pillow (PIL)
  - python-magic
  - markdown-it-py
  
Image Generation:
  - requests (for SD API)
  
Search & Tools:
  - google-api-python-client
  - PyGithub
  
Export:
  - reportlab (PDF export)
  - weasyprint (alternative)
```

**Interfaces:**
```python
# Provided REST APIs
POST /chat                      # Send message to AI
POST /upload                    # Upload & analyze file
POST /stop-generation           # Stop AI generation
POST /api/generate-image        # Generate image with SD
GET  /api/conversations         # Get conversations
GET  /api/conversation/<id>     # Get conversation details
DELETE /api/conversation/<id>   # Delete conversation
GET  /api/models                # List available models
POST /api/export-pdf            # Export chat to PDF
GET  /api/search                # Google/GitHub search

# Required APIs
- MongoDB: mongodb+srv://...
- Gemini API: https://generativelanguage.googleapis.com
- OpenAI API: https://api.openai.com
- Stable Diffusion: http://localhost:7861/sdapi/v1
- Google Search: https://www.googleapis.com/customsearch
- GitHub: https://api.github.com
```

**File Structure:**
```
ChatBot/
â”œâ”€â”€ app.py                      # Main Flask app
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ chatbot_engine.py       # Core engine
â”‚   â”œâ”€â”€ model_manager.py        # AI model switcher
â”‚   â”œâ”€â”€ file_handler.py         # File upload/analysis
â”‚   â””â”€â”€ tools/
â”‚       â”œâ”€â”€ search_google.py
â”‚       â””â”€â”€ search_github.py
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ mongodb_config.py       # MongoDB client
â”‚   â”œâ”€â”€ mongodb_helpers.py      # CRUD operations
â”‚   â””â”€â”€ mongodb_schema.py       # Schema docs
â”œâ”€â”€ Storage/
â”‚   â”œâ”€â”€ conversations/          # JSON files (backup)
â”‚   â”œâ”€â”€ uploaded_files/         # User uploads
â”‚   â””â”€â”€ generated_images/       # SD images
â””â”€â”€ templates/
    â””â”€â”€ index.html              # WebUI
```

**Current Status:**
- âœ… Multi-model support (5+ models)
- âœ… Auto-file analysis (up to 50MB)
- âœ… Stop generation
- âœ… Message versioning
- âœ… MongoDB integration
- âœ… Image generation
- âœ… Google/GitHub search
- âœ… PDF export
- âš ï¸ No streaming responses yet
- âš ï¸ No voice input/output yet

---

### 3. ğŸ“Š Text2SQL Service Component

**Vai trÃ²:** Natural Language to SQL Query Generation with AI Learning

```mermaid
graph TB
    subgraph Text2SQL Service
        API[Flask API Layer]
        SchemaParser[Schema Parser]
        KnowledgeBase[Knowledge Base]
        QueryGen[Query Generator]
        DBConnector[DB Connector]
        AILearner[AI Learning System]
        
        API --> SchemaParser
        API --> KnowledgeBase
        API --> QueryGen
        API --> DBConnector
        API --> AILearner
        
        QueryGen --> KnowledgeBase
        AILearner --> KnowledgeBase
    end
    
    SchemaParser --> ClickHouse[(ClickHouse)]
    SchemaParser --> MongoDB[(MongoDB)]
    SchemaParser --> PostgreSQL[(PostgreSQL)]
    
    DBConnector --> ClickHouse
    DBConnector --> MongoDB
    DBConnector --> PostgreSQL
    
    QueryGen --> GeminiAPI[Gemini API]
    
    KnowledgeBase --> LocalFiles[(JSON Files)]
```

**Dependencies:**
```yaml
Core Framework:
  - Flask 3.0+
  - Flask-CORS
  - python-dotenv
  
AI Models:
  - google-generativeai (Gemini 2.0 Flash)
  
Database Drivers:
  - clickhouse-driver
  - pymongo
  - psycopg2-binary (PostgreSQL)
  - mysql-connector-python
  
Schema Parsing:
  - sqlparse
  - json
  - pandas (for data preview)
  
Knowledge Base:
  - sentence-transformers (embeddings)
  - faiss-cpu (similarity search)
  
Utilities:
  - hashlib (schema hashing)
  - re (regex for SQL parsing)
```

**Interfaces:**
```python
# Provided REST APIs
POST /upload-schema             # Upload schema file
POST /parse-schema              # Parse schema from text
GET  /sample-questions          # Generate sample questions
POST /chat                      # Generate SQL from question
POST /execute-query             # Execute SQL query
POST /feedback                  # Save correct/wrong feedback
GET  /knowledge-base            # Get KB statistics
GET  /databases                 # List connected databases
POST /connect-database          # Add DB connection

# Required APIs
- Gemini API: https://generativelanguage.googleapis.com
- ClickHouse: tcp://localhost:9000
- MongoDB: mongodb://localhost:27017
- PostgreSQL: postgresql://localhost:5432
```

**File Structure:**
```
Text2SQL Services/
â”œâ”€â”€ app_simple.py               # Main Flask app
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ schema_parser.py        # Parse schema
â”‚   â”œâ”€â”€ query_generator.py      # Generate SQL
â”‚   â”œâ”€â”€ knowledge_base.py       # AI learning
â”‚   â””â”€â”€ db_connector.py         # DB connections
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ knowledge_base/         # Saved queries
â”‚   â”‚   â”œâ”€â”€ clickhouse.jsonl
â”‚   â”‚   â”œâ”€â”€ mongodb.jsonl
â”‚   â”‚   â””â”€â”€ postgresql.jsonl
â”‚   â””â”€â”€ schemas/                # Uploaded schemas
â””â”€â”€ templates/
    â””â”€â”€ index.html              # WebUI
```

**Current Status:**
- âœ… Multi-database support (ClickHouse, MongoDB, PostgreSQL, MySQL)
- âœ… AI learning system with Knowledge Base
- âœ… Sample question generation
- âœ… Deep thinking mode
- âœ… Vietnamese + English support
- âœ… Deploy on Render.com FREE tier
- âš ï¸ No vector DB yet (using simple similarity)
- âš ï¸ No query optimization suggestions

---

### 4. ğŸ™ï¸ Speech2Text Service Component

**Vai trÃ²:** Dual-model audio transcription with speaker diarization

```mermaid
graph TB
    subgraph Speech2Text Service
        GradioUI[Gradio Web UI]
        Preprocessor[Audio Preprocessor]
        Diarization[Speaker Diarization]
        WhisperEngine[Whisper Engine]
        PhoWhisperEngine[PhoWhisper Engine]
        Merger[Transcript Merger]
        Enhancer[Qwen Enhancer]
        
        GradioUI --> Preprocessor
        Preprocessor --> Diarization
        Diarization --> WhisperEngine
        Diarization --> PhoWhisperEngine
        WhisperEngine --> Merger
        PhoWhisperEngine --> Merger
        Merger --> Enhancer
    end
    
    WhisperEngine --> WhisperModel[(Whisper large-v3)]
    PhoWhisperEngine --> PhoWhisperModel[(PhoWhisper base)]
    Diarization --> PyannoteModel[(pyannote-diarization)]
    Enhancer --> QwenModel[(Qwen2.5-1.5B)]
    
    Enhancer --> FileStorage[(Output Files)]
```

**Dependencies:**
```yaml
Core Framework:
  - gradio >= 4.0
  - fastapi (Gradio uses)
  
Audio Processing:
  - librosa >= 0.10.0
  - soundfile >= 0.12.0
  - pydub >= 0.25.0
  - ffmpeg-python
  
ASR Models:
  - openai-whisper
  - transformers >= 4.36.0
  - torch >= 2.0.0
  - torchaudio
  
Diarization:
  - pyannote.audio >= 3.1.0
  - speechbrain >= 0.5.0
  
Enhancement:
  - transformers (Qwen2.5)
  
Utilities:
  - numpy
  - scipy
  - python-dotenv
```

**Interfaces:**
```python
# Gradio UI (Web Interface)
- Input: Audio file upload (MP3/WAV/M4A/FLAC)
- Output: Transcript with speaker labels
- Settings: Model selection, VAD, enhancement

# Internal Functions (Future REST API)
POST /transcribe                # Transcribe audio
GET  /models                    # List available models
GET  /transcription/<id>        # Get transcription result
DELETE /transcription/<id>      # Delete result
```

**File Structure:**
```
Speech2Text Services/
â”œâ”€â”€ app.py                      # Gradio app
â”œâ”€â”€ s2t/
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ transcriber.py      # Whisper transcription
â”‚   â”‚   â”œâ”€â”€ diarization.py      # Speaker diarization
â”‚   â”‚   â””â”€â”€ enhancer.py         # Qwen enhancement
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ audio_utils.py      # Audio preprocessing
â”‚       â””â”€â”€ text_utils.py       # Text formatting
â”œâ”€â”€ models/                     # Downloaded models
â”‚   â”œâ”€â”€ whisper-large-v3/
â”‚   â”œâ”€â”€ phowhisper-base/
â”‚   â”œâ”€â”€ pyannote-diarization/
â”‚   â””â”€â”€ qwen2.5-1.5b/
â”œâ”€â”€ output/                     # Transcription results
â””â”€â”€ data/                       # Input audio files
```

**Current Status:**
- âœ… Dual-model fusion (Whisper + PhoWhisper)
- âœ… Speaker diarization (pyannote.audio)
- âœ… Vietnamese fine-tuned (PhoWhisper)
- âœ… AI enhancement (Qwen2.5)
- âœ… VAD optimization (Silero VAD)
- âœ… GPU acceleration (CUDA)
- âœ… Multiple audio formats
- âš ï¸ No real-time streaming yet
- âš ï¸ No custom vocabulary training

---

### 5. ğŸ¨ Stable Diffusion Service Component

**Vai trÃ²:** AI Image Generation (Text-to-Image, Image-to-Image)

```mermaid
graph TB
    subgraph Stable Diffusion WebUI
        GradioUI[Gradio Web Interface]
        API[REST API]
        ModelLoader[Model Loader]
        LoRAManager[LoRA Manager]
        VAELoader[VAE Loader]
        Sampler[Sampler Engine]
        Upscaler[Upscaler]
        ControlNet[ControlNet]
        
        GradioUI --> ModelLoader
        API --> ModelLoader
        ModelLoader --> LoRAManager
        ModelLoader --> VAELoader
        ModelLoader --> Sampler
        Sampler --> Upscaler
        Sampler --> ControlNet
    end
    
    ModelLoader --> SDModels[(SD Models<br/>v1.5/SDXL)]
    LoRAManager --> LoRAFiles[(LoRA Models<br/>100+)]
    VAELoader --> VAEFiles[(VAE Models)]
    ControlNet --> ControlNetModels[(ControlNet<br/>15+ models)]
    
    Upscaler --> Output[(Generated Images)]
```

**Dependencies:**
```yaml
Core Framework:
  - gradio >= 3.50.0
  - fastapi
  
SD Core:
  - torch >= 2.0.0
  - torchvision
  - diffusers >= 0.21.0
  - transformers >= 4.36.0
  
Acceleration:
  - xformers >= 0.0.21
  - accelerate >= 0.24.0
  
Image Processing:
  - opencv-python
  - Pillow >= 10.0.0
  - numpy
  
Models:
  - safetensors >= 0.4.0
  - omegaconf
  
Utilities:
  - tqdm
  - einops
  - kornia
```

**Interfaces:**
```python
# Gradio UI
- Text-to-Image tab
- Image-to-Image tab
- Extras (upscaling, face restoration)
- Settings

# REST API (AUTOMATIC1111 API)
POST /sdapi/v1/txt2img          # Text to image
POST /sdapi/v1/img2img          # Image to image
GET  /sdapi/v1/sd-models        # List models
POST /sdapi/v1/options          # Set options
GET  /sdapi/v1/progress         # Get progress
POST /sdapi/v1/interrupt        # Stop generation
GET  /sdapi/v1/loras            # List LoRAs
GET  /sdapi/v1/samplers         # List samplers
```

**File Structure:**
```
stable-diffusion-webui/
â”œâ”€â”€ webui.py                    # Main entry point
â”œâ”€â”€ modules/
â”‚   â”œâ”€â”€ api/                    # REST API
â”‚   â”œâ”€â”€ processing.py           # Image generation
â”‚   â”œâ”€â”€ sd_models.py            # Model management
â”‚   â”œâ”€â”€ sd_samplers.py          # Samplers
â”‚   â””â”€â”€ extras.py               # Upscaling, etc.
â”œâ”€â”€ extensions/
â”‚   â””â”€â”€ sd-webui-controlnet/    # ControlNet
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ Stable-diffusion/       # Base models
â”‚   â”œâ”€â”€ Lora/                   # LoRA models
â”‚   â”œâ”€â”€ VAE/                    # VAE models
â”‚   â””â”€â”€ ControlNet/             # ControlNet models
â””â”€â”€ outputs/
    â””â”€â”€ txt2img-images/         # Generated images
```

**Current Status:**
- âœ… Text-to-Image generation
- âœ… Image-to-Image modification
- âœ… LoRA support (100+ models)
- âœ… VAE support
- âœ… ControlNet (15+ models)
- âœ… Multiple samplers
- âœ… Upscaling (4x)
- âœ… Face restoration
- âœ… REST API enabled
- âœ… CUDA 12.1 optimized
- âš ï¸ No batch processing UI
- âš ï¸ No training support yet

---

## ğŸ”— Communication Patterns

### 1. Client-Server (REST APIs)

```mermaid
sequenceDiagram
    Client->>Hub: HTTP Request
    Hub->>Service: Forward request
    Service->>External API: Call if needed
    External API-->>Service: Response
    Service-->>Hub: JSON response
    Hub-->>Client: JSON response
```

**Protocol:** HTTP/1.1  
**Format:** JSON  
**Authentication:** None (future: JWT)  
**Rate Limit:** None (future: Redis-based)

---

### 2. Service-to-Service (Internal)

```mermaid
sequenceDiagram
    ChatBot->>Stable Diffusion: POST /sdapi/v1/txt2img
    Stable Diffusion-->>ChatBot: {image_url, seed}
    ChatBot->>ImgBB: Upload image
    ImgBB-->>ChatBot: {cloud_url}
    ChatBot->>MongoDB: Save metadata
```

**Protocol:** HTTP (localhost)  
**Format:** JSON  
**Timeout:** 60s (configurable)

---

### 3. Database Access

```mermaid
graph LR
    Service[Service] --> Driver[DB Driver]
    Driver --> Pool[Connection Pool]
    Pool --> DB[(Database)]
    
    style Service fill:#8B5CF6,color:#fff
    style DB fill:#3B82F6,color:#fff
```

**Pattern:** Connection Pooling  
**Libraries:** pymongo, psycopg2, clickhouse-driver  
**Max Connections:** 10-50 per service

---

## ğŸ“¦ Deployment Architecture

### Option 1: Local Development (Current)

```mermaid
graph TB
    subgraph Local Machine
        subgraph Python Environments
            venv1[venv_chatbot]
            venv2[Text2SQL]
            venv3[venv_s2t]
            venv4[venv_sd]
        end
        
        subgraph Processes
            P1[ChatBot :5001]
            P2[Text2SQL :5002]
            P3[Speech2Text :7860]
            P4[Stable Diffusion :7861]
            P5[Hub :3000]
        end
        
        subgraph Data
            Files[(Local Files)]
            MongoDB[(MongoDB Atlas)]
        end
        
        venv1 --> P1
        venv2 --> P2
        venv3 --> P3
        venv4 --> P4
        
        P1 --> Files
        P1 --> MongoDB
        P2 --> Files
        P3 --> Files
        P4 --> Files
    end
    
    Browser[ğŸŒ Browser] --> P5
    P5 --> P1
    P5 --> P2
    P5 --> P3
    P5 --> P4
```

**Pros:** âœ… Easy setup, full control  
**Cons:** âŒ Not scalable, manual process management

---

### Option 2: Docker Compose (Recommended)

```mermaid
graph TB
    subgraph Docker Host
        subgraph Containers
            C1[chatbot:5001]
            C2[text2sql:5002]
            C3[speech2text:7860]
            C4[stable-diffusion:7861]
            C5[hub:3000]
            C6[nginx:80]
            C7[redis:6379]
        end
        
        subgraph Volumes
            V1[chatbot_data]
            V2[text2sql_data]
            V3[speech2text_data]
            V4[sd_models]
        end
        
        Network[docker_network]
        
        C1 -.-> Network
        C2 -.-> Network
        C3 -.-> Network
        C4 -.-> Network
        C5 -.-> Network
        C6 -.-> Network
        C7 -.-> Network
        
        C1 --> V1
        C2 --> V2
        C3 --> V3
        C4 --> V4
    end
    
    Internet[ğŸŒ Internet] --> C6
    C6 --> C5
```

**Pros:** âœ… Easy deployment, isolation, portability  
**Cons:** âš ï¸ Resource overhead, learning curve

**docker-compose.yml:**
```yaml
version: '3.8'
services:
  hub:
    build: ./src
    ports: ["3000:3000"]
    depends_on: [chatbot, text2sql]
  
  chatbot:
    build: ./ChatBot
    ports: ["5001:5001"]
    environment:
      - GEMINI_API_KEY=${GEMINI_API_KEY}
    volumes:
      - chatbot_data:/app/Storage
  
  # ... other services
```

---

### Option 3: Cloud Deployment (Production)

```mermaid
graph TB
    subgraph Cloud Provider - Azure/AWS/GCP
        subgraph Load Balancer
            LB[Azure Load Balancer]
        end
        
        subgraph App Services
            AS1[ChatBot VM]
            AS2[Text2SQL VM]
            AS3[Speech2Text VM]
            AS4[Stable Diffusion GPU VM]
        end
        
        subgraph Storage
            Blob[Azure Blob Storage]
            SQL[Azure PostgreSQL]
            Cache[Azure Redis Cache]
        end
        
        subgraph CDN
            CDN[Azure CDN]
        end
        
        LB --> AS1
        LB --> AS2
        LB --> AS3
        LB --> AS4
        
        AS1 --> SQL
        AS1 --> Blob
        AS1 --> Cache
        
        AS2 --> SQL
        AS2 --> Cache
        
        AS3 --> Blob
        AS4 --> Blob
        
        CDN --> Blob
    end
    
    Users[ğŸŒ Users] --> CDN
    Users --> LB
```

**Estimated Cost (Azure - 1K users):**
- VMs: $200-500/month
- Storage: $50-100/month
- Database: $100-200/month
- Bandwidth: $50-100/month
- **Total:** ~$400-900/month

---

## ğŸ” Security Components

### 1. Authentication & Authorization (Future)

```mermaid
graph TB
    User[ğŸ‘¤ User] --> Login[ğŸ” Login]
    Login --> JWT[Generate JWT]
    JWT --> Client[Client stores token]
    Client --> Request[Authenticated Request]
    Request --> Verify[Verify JWT]
    Verify --> Service[Access Service]
    
    style Login fill:#10B981,color:#fff
    style Verify fill:#EF4444,color:#fff
```

**Implementation Plan:**
- Library: `PyJWT`, `Flask-JWT-Extended`
- Token expiry: 24 hours
- Refresh token: 7 days

---

### 2. Rate Limiting (Future)

```mermaid
graph TB
    Request[ğŸ“¨ Request] --> Redis[âš¡ Redis Counter]
    Redis --> Check{Under limit?}
    Check -->|Yes| Allow[âœ… Process]
    Check -->|No| Reject[âŒ 429 Too Many Requests]
    
    style Allow fill:#10B981,color:#fff
    style Reject fill:#EF4444,color:#fff
```

**Limits:**
- Free tier: 100 req/hour
- Paid tier: 1000 req/hour
- Enterprise: Unlimited

---

## ğŸ“ˆ Scalability Strategies

### Horizontal Scaling

```mermaid
graph TB
    LB[Load Balancer] --> S1[Service Instance 1]
    LB --> S2[Service Instance 2]
    LB --> S3[Service Instance 3]
    
    S1 --> DB[(Shared Database)]
    S2 --> DB
    S3 --> DB
    
    S1 --> Cache[(Redis Cluster)]
    S2 --> Cache
    S3 --> Cache
```

**Benefits:**
- Handle more concurrent users
- Fault tolerance (if one instance fails)
- Auto-scaling based on load

---

## ğŸ“ Monitoring & Observability (Future)

### Proposed Stack:

```mermaid
graph TB
    subgraph Services
        S1[ChatBot]
        S2[Text2SQL]
        S3[Speech2Text]
        S4[Stable Diffusion]
    end
    
    subgraph Monitoring
        Prometheus[ğŸ“Š Prometheus<br/>Metrics Collection]
        Grafana[ğŸ“ˆ Grafana<br/>Visualization]
        Loki[ğŸ“ Loki<br/>Log Aggregation]
        Jaeger[ğŸ” Jaeger<br/>Distributed Tracing]
    end
    
    S1 --> Prometheus
    S2 --> Prometheus
    S3 --> Prometheus
    S4 --> Prometheus
    
    Prometheus --> Grafana
    
    S1 --> Loki
    S2 --> Loki
    S3 --> Loki
    S4 --> Loki
    
    S1 --> Jaeger
    S2 --> Jaeger
    S3 --> Jaeger
    S4 --> Jaeger
```

**Metrics to track:**
- Request rate (req/sec)
- Response time (p50, p95, p99)
- Error rate (%)
- CPU/Memory usage
- Active connections
- Model inference time

---

## ğŸ¯ Summary

| Aspect | Count | Status |
|:-------|:------|:-------|
| **Core Services** | 4 | âœ… Production |
| **Gateway** | 1 | âš ï¸ Basic |
| **Databases** | 3 | âœ… Active |
| **External APIs** | 7 | âœ… Integrated |
| **Deployment Options** | 3 | âœ… Documented |
| **Authentication** | 0 | ğŸš§ Planned |
| **Monitoring** | 0 | ğŸš§ Planned |

---

<div align="center">

[â¬…ï¸ Previous: ER Diagram](05_er_diagram.md) | [Back to Index](README.md) | [â¡ï¸ Next: Activity Diagram](07_activity_diagram.md)

</div>
