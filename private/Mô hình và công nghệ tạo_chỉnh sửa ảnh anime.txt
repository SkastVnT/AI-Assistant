Mô hình và công ngh? t?o/ch?nh s?a ?nh anime
H? sinh thái AI cho ?nh anime ngày nay bao g?m nhi?u mô hình và công c? chuyên bi?t d? t?o và ch?nh s?a ?nh phong cách anime v?i ch?t lu?ng cao. Các mô hình text-to-image (chuy?n d?i van b?n sang ?nh) nhu Stable Diffusion du?c tinh ch?nh cho anime là n?n t?ng chính. Ví d?, Waifu Diffusion v1.4 (mô hình Stable Diffusion tinh ch?nh trên ?nh anime ch?t lu?ng cao) du?c phát hành v?i gi?y phép CreativeML OpenRAIL-M[1][2]. Tuong t?, dòng Anything (nhu Anything V3.0 và V4.0) là các latent diffusion model cho ?nh anime chi ti?t cao, cung dùng gi?y phép OpenRAIL-M[3][4][5][6]. Dòng Animagine XL (ví d? Animagine XL 3.1) là mô hình SDXL mã ngu?n m?, t?p trung vào t?o anime v?i gi?i ph?u tay t?t hon và nh?n th?c ý ni?m cao, gi?y phép CreativeML OpenRAIL++[7][8]. Ngoài ra, có các mô hình SDXL chuyên bi?t khác nhu Stable Diffusion XL Anime V5 (d?a trên Animagine, gi?i pháp SFT d? tang ch?t lu?ng anime) v?i gi?y phép Fair-IA-Public-1.0[9][10]. Nhà cung c?p d?ch v? NovelAI cung có các mô hình d?u ra cao: ví d? NovelAI Diffusion Anime V2 (d?a trên SD1.5) dã du?c công b? cho m?c dích nghiên c?u v?i gi?y phép CreativeML OpenRAIL-M và CC BY-NC-SA[11][12]. (NovelAI còn có các mô hình V3/V4 proprietary ch?y trên h? th?ng c?a h? v?i ch?t lu?ng r?t cao[13].)
* Waifu Diffusion v1.4 - mô hình Latent Diffusion tinh ch?nh trên ?nh anime[1]. ?ng d?ng cho text-to-image và image-to-image, gi?y phép CreativeML OpenRAIL-M cho phép s? d?ng r?ng rãi[2].
* Anything V3.0 / V4.0 - mô hình "dành cho otaku", t?o ?nh anime c?c k? chi ti?t ch? v?i vài t? khóa (ví d? "anime girl: ...")[3][5]. C? hai phiên b?n này d?u dùng CreativeML OpenRAIL-M (mi?n phí s? d?ng thuong m?i)[4][6].
* Animagine XL 3.1 - mô hình SDXL mã ngu?n m?, t?p trung t?o ?nh anime v?i gi?i ph?u và chi ti?t t?t hon[7][8]. Gi?y phép CreativeML OpenRAIL++-M, tr?ng s? cho phép phân ph?i và s? d?ng v?i ràng bu?c h?n ch? n?i dung gây h?i.
* Stable Diffusion XL Anime V5 - mô hình SDXL tinh ch?nh (SFT) d?a trên Animagine 3.1, c?i thi?n màu s?c anime và gi?i ph?u co th?[10]. Gi?y phép Fair-IA-Public-1.0-SD (mô hình SDXL h?n ch? thuong m?i).
* NovelAI Diffusion Anime V2 - mô hình th? h? anime r?t m?nh trên n?n SD1.5[11]. M? cho nghiên c?u/cá nhân, gi?y phép CreativeML OpenRAIL-M k?t h?p v?i CC BY-NC-SA (không dùng cho m?c dích thuong m?i)[12].
* NovelAI Anime V3 - mô hình anime th? h? tru?c, d?a trên SDXL v?i kh? nang di?u khi?n d? chú ý (tag ordering) cao[13]. Ch? có trong d?ch v? c?a NovelAI (không phát hành công khai), nhung dáng nh?c t?i ch?t lu?ng d?u ra.
* Các mô hình khác: Ngoài ra có nhi?u mô hình LoRA (low-rank adapters) chuyên v? phong cách nh?t d?nh (ví d? các LoRA "Shoujo" hay "Pastel Mix" cho tông màu anime), các mô hình ?n d?nh (Stable Diffusion 2.1), và VAE (nhu SD-VAE-Anime) d? nâng cao ch?t lu?ng ?nh anime.
Uu di?m/Nhu?c di?m: Các mô hình trên d?u du?c hu?n luy?n trên t?p d? li?u anime l?n (thu?ng là ?nh t? booru, Pixiv, v.v.), cho phép t?o ?nh anime s?c nét, giàu chi ti?t. Tuy nhiên, chúng có th? thiên v? phong cách "cute"/bright (ví d? Waifu Diffusion) và dôi khi kém da d?ng v? b?i c?nh. Model SDXL thu?ng t?o ch?t lu?ng cao nhung n?ng ph?n c?ng. Gi?y phép RAIL cho phép t? do thuong m?i v?i di?u ki?n tuân th? lu?t (không t?o n?i dung b?t h?p pháp)[2].
Mô hình Image-to-Image và ch?nh s?a ?nh
Ð? ch?nh s?a ?nh theo hu?ng anime, c?n các mô hình h? tr? image-to-image và instruction-based editing. Ví d?, InstructPix2Pix (tri?n khai m? MIT) cho phép b?n nh?p ?nh và ch? d?n b?ng van b?n d? ch?nh s?a (nhu "thêm pháo hoa trên b?u tr?i" ho?c "bi?n cô gái thành phong cách anime")[14]. Mô hình này du?c phát tri?n d?a trên fine-tune c?a Stable Diffusion theo hu?ng instruction-following. Qwen-Image-Edit (Apache-2.0) là mô hình da-modal (h? tr? c? ngôn ng? Trung-Anh) dùng cho ch?nh s?a ?nh: nó dua ?nh vào hai kênh x? lý (Qwen2.5-VL cho semantic và VAE Encoder cho appearance), t? dó có th? th?c hi?n các ch?nh s?a ph?c t?p nhu "thay d?i màu s?c, xoay v?t th?, chuy?n phong cách (style transfer) mà v?n gi? tính nh?t quán c?a ?nh"[15]. Qwen-Image-Edit du?c dánh giá SOTA trong các tác v? ch?nh s?a (ví d? thêm ch? trên bi?n hi?u gi? nguyên font size/style)[16][17]. Ngoài ra, k? thu?t Prompt-to-Prompt (Google) cung ph? bi?n d? ch?nh s?a c?u trúc ?nh mà không c?n hu?n luy?n thêm.
* InstructPix2Pix (MIT) - tri?n khai pytorch c?a phuong pháp theo bài báo [InstructPix2Pix: Learning to Follow Image Editing Instructions]. Cho phép ch?nh ?nh theo l?nh mô t?, ví d? "d?i màu tóc thành d?". Mã ngu?n m?, GPL-3.0 cho repo g?c (h? tr? A1111).
* Qwen-Image-Edit (Apache-2.0) - mô hình ch?nh s?a da ch?c nang, ch?y trên diffusers. H? tr? c? ch?nh semantic (ví d? xoay d?i tu?ng, thêm hình v?) và appearance (thay d?i y?u t? c? th?, gi? l?i ph?n còn l?i)[15]. Ph? bi?n ? Trung Qu?c (h? tr? prompt Trung-Anh).
* ControlNet chung - Công ngh? ControlNet cho phép di?u khi?n ch?t hon d?u vào ?nh (du?ng nét, pose, depth, segmentation, v.v.). Các mô hình ControlNet g?c (canny, depth, pose, HED, normal, mlsd, scribble, segmentation) giúp chuy?n ?nh tham kh?o thành input d? t?o ?nh[18]. Trên co s? này, dã có các ControlNet chuyên bi?t cho anime (ví d? anime line art, anime style, anime pose) - dóng vai trò nhu "adapter" dua d?c trung anime vào quá trình sinh ?nh[19].
* Paint-by-example / Segment Anything + Inpainting - S? d?ng Segment Anything d? tách d?i tu?ng và sau dó dùng SD inpaint ho?c ControlNet d? ch?nh s?a t?ng ph?n.
* (Các mô hình khác: P2P, DreamBooth Inpainting, GAN kh? nhi?u, v.v. tùy giao di?n.)
Uu/Nhu?c: Nh?ng mô hình trên cho phép ch?nh s?a ?nh anime m?t cách linh ho?t (ví d? chèn c?nh v?t m?i, d?i tóc/m?t, style transfer sang phong cách Ghibli) mà không c?n ki?n th?c d? h?a. Tuy nhiên, k?t qu? ph? thu?c nhi?u vào prompt và ?nh g?c. M?t s? k? thu?t (nhu Prompt-to-Prompt) c?n ph?n m?m chuyên d?ng (A1111, ComfyUI). Nhìn chung, InstructPix2Pix và Qwen-Image-Edit dang d?n d?u v? kh? nang theo l?nh t? nhiên và gi? c?u trúc ?nh.
Gi? phong cách và nh?n d?ng nhân v?t
Các công c? trên còn h? tr? gi? phong cách anime nh?t quán và nh?n d?ng nhân v?t gi?a nhi?u ?nh. Ví d?, IP-Adapter FaceID (m?t m? r?ng c?a ControlNet) ch? trích xu?t các d?c trung khuôn m?t t? ?nh g?c và áp d?ng vào ?nh sinh[20]. B?ng cách n?p LoRA tuong ?ng (FaceID LoRA) và dùng preprocessor "ip-adapter_face_id", mô-dun này duy trì d?c di?m khuôn m?t nhân v?t khi thay d?i t?o ?nh m?i. Tuong t?, k? thu?t InstantID hay PuLID (dù chua có mã ngu?n m? r?ng rãi) nh?m t?o ?nh v?i nh?n d?ng nhân v?t du?c b?o toàn. Ngoài ra, ngu?i dùng có th? hu?n luy?n riêng LoRA ho?c DreamBooth trên ?nh anime c?a m?t nhân v?t d? khi sinh ?nh m?i v?n gi? d?c di?m g?c.
* IP-Adapter FaceID (CreativeML OpenRAIL-M trên HF) - adapter gi? các d?c trung khuôn m?t t? ?nh g?c[20]. Ví d? HuggingFace có s?n các LoRA FaceID Plus dành cho SD v1.5/SDXL[20], dùng kèm v?i ControlNet ip-adapter_face_id.
* InstantID / PuLID - phuong pháp zero-shot (không h?c l?i) d? b?o toàn nhân d?ng t? m?t ?nh tham chi?u. InstantID dã du?c công b? nghiên c?u (OpenVINO doc) và gi? khuôn m?t m?t cách nhanh chóng.
* LoRA/DreamBooth - t? h?c trên t?p hình nhân v?t anime (du?c g?n tag d?nh danh) d? khi sinh ?nh, mô hình nh? guong m?t.
Nh? các phuong pháp này, khi ch?p ho?c sinh nhi?u ?nh cùng nhân v?t anime, h? th?ng có th? t?o ra các hình m?i khác c?nh mà v?n nh?n ra du?c ngu?i trong ?nh.
ControlNet và Adapter nâng cao
ControlNet là công ngh? c?t lõi d? di?u khi?n chi ti?t trong sinh ?nh. Các mô hình ControlNet g?c c?a lllyasviel (canny, HED, pose, depth,...) li?t kê trong repo [18] cho th?y kh? nang di?u khi?n b?ng c?u trúc d?u vào (biên c?nh text prompt). V?i phong cách anime, dã có các bi?n th? Anime ControlNet: ví d? d? án "lint/anime_control" cung c?p các m?ng no-ron anime_control_dreamshaper (nhu "canny anime" hay "style anime") d? thêm di?u ki?n phong cách anime[19]. Theo hu?ng tuong t?, Style Adapter (mô hình di?u ch?nh phong cách) là khái ni?m nghiên c?u liên quan t?i vi?c trích xu?t d?c trung phong cách t? ?nh tham chi?u và tiêm vào mô hình SD[21]. Trong th?c hành, IP-Adapter và Style-Adapter du?c dùng d? tách r?i ?nh phong cách và n?i dung nh?m cho phép "style transfer".
* ControlNet Anime - các mô hình ti?n hu?n luy?n (canny-anime, style-anime) giúp thêm hu?ng d?n phong cách (ví d? v? du?ng nét ho?c áp d?ng style)[19]. Ví d?, dùng m?t t?m ?nh n?n den (hình vuông) v?i anime_control d? ch? áp style anime cho ?nh m?i.
* IP-Adapter - dã d? c?p FaceID; ngoài ra có IP-Adapter chung cho phép dua ?nh làm prompt (image prompt) tuong t? Midjourney[22].
* Style-Adapter - các module nh? d? tiêm d?c trung phong cách t? ?nh tham chi?u vào quá trình khu?ch tán, nh? dó ?nh sinh gi? du?c style mong mu?n[21].
* Adapter-free (chi?t xu?t attention) - nhu phuong pháp "swap self-attention" ho?c "style swap" trong nghiên c?u, tuy chua ph? bi?n r?ng trong c?ng d?ng.
Nh? k?t h?p ControlNet và các adapter, ngu?i dùng có th? di?u khi?n chính xác c?u trúc (pose, layout) và phong cách (màu s?c, nét v?) c?a ?nh anime t?o ra. Các plugin nhu sd-webui-controlnet và ComfyUI có s?n các block d? tích h?p nh?ng phuong pháp này.
D? li?u và g?n th? t? d?ng
Ð? hu?n luy?n và tìm ki?m ?nh anime, h? th?ng c?n b? d? li?u l?n. Ngu?n ph? bi?n nh?t là ?nh trên các Booru (Danbooru2018, Gelbooru, Danbooru chính th?c) ho?c t? Pixiv, NicoNico. Ngu?i dùng cung t? suu t?p ?nh t? fandom ho?c ch?p màn hình. Ngoài ra, có th? t?o ?nh anime b?ng AI (v?i b?n quy?n m?) r?i dùng làm d? li?u. Khi thu th?p, vi?c t? g?n tag (nhu thu?c tính, nhân v?t) r?t h?u ích. Các công c? nhu DeepDanbooru (m?ng CNN g?n tag Booru) và WD14 Tagger (h? th?ng dùng SD1.4 d? gán tag) du?c tích h?p trong nhi?u giao di?n nhu A1111. Ví d?, extension "stable-diffusion-webui-wd14-tagger" h? tr? g?n tag Booru t? d?ng cho hình, t?i mô hình WaifuDiffusion-1.4 Tagger ho?c DeepDanbooru t? HuggingFace khi ch?y l?n d?u[23]. Các gán nhãn này giúp tìm ki?m theo nhân v?t ho?c phong cách (ví d? tìm ?nh t?t c? tag "blue hair", "forest background").
* Danbooru/Gelbooru - b? ?nh anime có g?n tag phong phú (Danbooru2018 ~3 tri?u ?nh) dùng d? hu?n luy?n và gán th?.
* DeepDanbooru - mô hình CNN n?i ti?ng (KichangKim) g?n tag anime t? ?nh, nhi?u nhãn (m? thu?t, nhân v?t, tình hu?ng).
* WD14 Tagger (MrSmilingWolf) - g?n tag theo embedding c?a Stable Diffusion 1.4 (dào t?o trên Danbooru)[23].
* Booru Tagger - m?t s? project khác (nhu Extension A1111) cung tích h?p g?n tag t? d?ng.
* Script/API - có th? t? ch?y DeepDanbooru offline d? t?o nhãn cho b? ?nh do AI t?o ra.
Các công c? và giao di?n
Ð? s? d?ng các mô hình trên m?t cách ti?n l?i, có th? dùng các giao di?n ph? bi?n:
* AUTOMATIC1111 WebUI (A1111) - giao di?n web ph? bi?n nh?t cho Stable Diffusion. H? tr? nhi?u plugin (ControlNet, LoRA, tagger) và mô hình anime. Ví d?, plugin WD14-Tagger[23], ControlNet Extension, AnimeMix, ngâm Ho?c Fooocus - là m?t frontend nh?, t?p trung t?i uu t?c d? và tr?i nghi?m.
* ComfyUI - giao di?n phi tuy?n (node-based) cho phép tùy bi?n quy trình sinh ?nh. ComfyUI h? tr? các node s?n có cho ControlNet, IP-Adapter, AnimateDiff, v.v., giúp xây d?ng workflow ch?nh s?a anime ph?c t?p.
* HuggingFace Spaces / ModelScope - m?t s? mô hình anime du?c tri?n khai du?i d?ng ?ng d?ng web (Spaces), có th? dùng th? mà không c?n cài d?t.
* Script/Docker - nhi?u project (nhu harubaru/waifu-diffusion) cung c?p mã và Dockerfile d? t? train/tri?n khai.
* Xây UI riêng - n?u c?n tích h?p trong s?n ph?m, có th? dùng các thu vi?n nhu diffusers (HF) d? g?i mô hình và xây UI tùy ý.
Nh? nh?ng công c? này, c? ngu?i dùng bình thu?ng và nhà phát tri?n d?u có th? k?t h?p linh ho?t các mô hình, adapter và lu?ng x? lý (workflow) d? t?o/ch?nh ?nh anime. Ví d?, hu?ng d?n lint/anime_control cho th?y cách thêm style anime vào WebUI ch? v?i vi?c t?i các weight và config cho ControlNet[24].
H? tr? NSFW và R18
H?u h?t mô hình anime mã ngu?n m? hi?n nay (ví d? WaifuDiffusion, Anything, Animagine,...) du?c phát hành du?i gi?y phép RAIL (nhu CreativeML OpenRAIL-M[2]) - cho phép s? d?ng thuong m?i mi?n là tuân th? lu?t. Gi?y phép này không c?m t?o n?i dung adult n?u h?p pháp (không vi ph?m pháp lu?t d?a phuong). Vì v?y, khi ch?y c?c b? (offline), mô hình s? không b? ki?m duy?t n?i dung nhu các d?ch v? tr?c tuy?n. Ngu?i dùng có th? t?o và ch?nh ?nh NSFW/R18 t? do, mi?n là trách nhi?m tuân th? pháp lu?t thu?c v? h?. Tuy nhiên, n?u dùng mô hình qua API ho?c giao di?n có filter (nhu nhóm NSFW filter c?a Stability), c?n vô hi?u b? l?c (ví d? A1111 có th? t?t Safe-Check). Ngoài ra, m?t s? mô hình ho?c LoRA c? th? (ví d? LoRA theo ch? d? adult c?a c?ng d?ng) cung có th? du?c phát tri?n riêng ph?c v? nhu c?u này.
Tóm l?i, h? th?ng m? này cho phép linh ho?t t?o ?nh n?i dung nh?y c?m mà không b? ràng bu?c ki?m duy?t - di?u ki?n là ngu?i dùng t? ch?u trách nhi?m theo gi?y phép RAIL và pháp lu?t[2].
Ngu?n tham kh?o: Các thông tin trên du?c t?ng h?p t? tài li?u và mã ngu?n công khai: ví d? Waifu Diffusion trên GitHub/HuggingFace[25][1], các mô hình trên HuggingFace[10][11], tài li?u ComfyUI/ControlNet[20][19], và hu?ng d?n tích h?p trong AUTOMATIC1111[23]. Nhi?u nghiên c?u và c?ng d?ng (c? trên GitHub, Reddit, X/Twitter c?a các tác gi?) cung cung c?p thêm ví d? và mô hình m?i trong linh v?c ?nh anime. Các mô hình và plugin du?c d? c?p ? trên d?u có liên k?t tuong ?ng d? ngu?i d?c tìm hi?u thêm.

[1] [2] hakurei/waifu-diffusion-v1-4 · Hugging Face
https://huggingface.co/hakurei/waifu-diffusion-v1-4
[3] [4] admruul/anything-v3.0 · Hugging Face
https://huggingface.co/admruul/anything-v3.0
[5] [6] xyn-ai/anything-v4.0 · Hugging Face
https://huggingface.co/xyn-ai/anything-v4.0
[7] [8] cagliostrolab/animagine-xl-3.1 · Hugging Face
https://huggingface.co/cagliostrolab/animagine-xl-3.1
[9] [10] bdsqlsz/stable-diffusion-xl-anime-V5 · Hugging Face
https://huggingface.co/bdsqlsz/stable-diffusion-xl-anime-V5
[11] [12] NovelAI/nai-anime-v2 · Hugging Face
https://huggingface.co/NovelAI/nai-anime-v2
[13]  | NovelAI Documentation
https://docs.novelai.net/en/image/models/
[14] GitHub - xuduo35/InstructPix2Pix: Pytorch implementation of 'InstructPix2Pix Learning to Follow Image Editing Instructions'
https://github.com/xuduo35/InstructPix2Pix
[15] [16] [17] Qwen/Qwen-Image-Edit · Hugging Face
https://huggingface.co/Qwen/Qwen-Image-Edit
[18] lllyasviel/ControlNet · Hugging Face
https://huggingface.co/lllyasviel/ControlNet
[19] [24] lint/anime_control · Hugging Face
https://huggingface.co/lint/anime_control
[20] [1.1.428] IP-Adapter FaceID · Mikubill sd-webui-controlnet · Discussion #2442 · GitHub
https://github.com/Mikubill/sd-webui-controlnet/discussions/2442
[21] : Free Lunch towards Style-Preserving in Text-to-Image Generation
https://arxiv.org/html/2404.02733v1
[22] IP-Adapters: All you need to know - Stable Diffusion Art
https://stable-diffusion-art.com/ip-adapter/
[23] GitHub - kawalain/stable-diffusion-webui-wd14-tagger: Labeling extension for Automatic1111's Web UI
https://github.com/kawalain/stable-diffusion-webui-wd14-tagger
[25] GitHub - harubaru/waifu-diffusion: stable diffusion finetuned on weeb stuff
https://github.com/harubaru/waifu-diffusion
