# Version Information

**Project:** Speech-to-Text System  
**Branch:** VistralS2T  
**Version:** 3.6.0  
**Release Date:** October 27, 2025

## System Components

- **Whisper:** large-v3 (OpenAI)
- **PhoWhisper:** large (VinAI)
- **Fusion Model:** Qwen2.5-1.5B-Instruct (Alibaba)
- **Python:** 3.10.6 (via pyenv)
- **CUDA:** 11.8 (recommended)

## Changelog

### v3.6.0 (2025-10-27) - Code Restructuring & Modular Architecture
- ðŸŽ¨ **NEW:** Modular architecture with separated concerns
  - `models/` - AI model wrappers (whisper, phowhisper, qwen, diarization)
  - `pipelines/` - Processing workflows (7 pipelines reorganized)
  - `services/` - Business logic layer (prepared for future use)
  - `prompts/` - Prompt engineering (renamed from prompt_engineering)
- ðŸŽ¨ **NEW:** File reorganization for better maintainability
  - Moved: `llm/*_client.py` â†’ `models/*_model.py`
  - Moved: `run_*.py` â†’ `pipelines/*_pipeline.py`
  - Renamed: `prompt_engineering/` â†’ `prompts/`
- ðŸ“ **IMPROVED:** Import path updates
  - Changed: `app.core.llm` â†’ `app.core.models`
  - Updated: 9+ files with corrected import paths
  - Fixed: All test files with new imports
- ðŸ“ **IMPROVED:** Code organization
  - Clear dependency hierarchy
  - Isolated components for testing
  - Scalable structure for future growth
- ðŸ“š **DOCS:** Comprehensive documentation
  - New: `RESTRUCTURING_COMPLETE.md` with detailed migration guide
  - Updated: `README.md` completely rewritten for v3.6
  - Added: Architecture diagrams and examples

### v3.5.0 (2025-10-24) - VAD Optimization
- âš¡ **NEW:** Voice Activity Detection with Silero VAD
- âš¡ **NEW:** 30-50% faster processing with silence filtering
- ðŸ”§ **FIXED:** Diarization timing display (was showing 0.00s)
- ðŸ”§ **FIXED:** WebUI progress broadcasting issues
- ðŸ”§ **IMPROVED:** Docker multi-stage builds for smaller images
- ðŸ“š **DOCS:** VERSION_3.5_UPGRADE_GUIDE.py with upgrade instructions

### v3.0.0 (2025-10-22) - VistralS2T
- âœ¨ **NEW:** Qwen2.5-1.5B-Instruct for smart fusion
- âœ¨ **NEW:** 3-role speaker separation (System/Employee/Customer)
- âœ¨ **NEW:** Dual transcription with merge
- âœ¨ **NEW:** Complete project rebuild system
- âœ¨ **NEW:** Docker deployment
- âœ¨ **NEW:** Pyenv integration
- ðŸ”§ **IMPROVED:** Clean project structure
- ðŸ”§ **IMPROVED:** Comprehensive health checks
- ðŸ”§ **IMPROVED:** Better error handling
- ðŸ“š **DOCS:** Complete documentation overhaul

### v2.0.0 (Previous)
- Gemini AI fusion
- T5 model support
- FastAPI web service

### v1.0.0 (Initial)
- Basic Whisper transcription
- PhoWhisper Vietnamese support
- Rule-based fusion

## Dependencies

See `requirements.txt` for full list.

Key packages:
- torch >= 2.0.0
- transformers >= 4.35.0
- faster-whisper >= 0.10.0
- librosa >= 0.10.0

## License

MIT License

## Authors

- **SkastVnT** - Main developer
- Branch: VistralS2T
- Repository: https://github.com/SkastVnT/Speech2Text

## Support

- **Issues:** https://github.com/SkastVnT/Speech2Text/issues
- **Documentation:** See README.md and QUICKREF.md
- **Health Check:** `python check.py`
