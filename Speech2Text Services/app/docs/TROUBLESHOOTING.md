# üõ†Ô∏è TROUBLESHOOTING GUIDE

## ‚ùå L·ªói Th∆∞·ªùng G·∫∑p v√† C√°ch Kh·∫Øc Ph·ª•c

### 1. L·ªói cuDNN DLL

**Tri·ªáu ch·ª©ng:**
```
Could not locate cudnn_ops64_9.dll
Invalid handle. Cannot load symbol cudnnCreateTensorDescriptor
```

**Nguy√™n nh√¢n:** PyTorch phi√™n b·∫£n CPU-only ƒëang ƒë∆∞·ª£c s·ª≠ d·ª•ng thay v√¨ CUDA.

**Gi·∫£i ph√°p:**
```powershell
# G·ª° PyTorch hi·ªán t·∫°i
pip uninstall torch torchaudio torchvision -y

# C√†i PyTorch v·ªõi CUDA support
pip install torch torchaudio --index-url https://download.pytorch.org/whl/cu121

# Ki·ªÉm tra
python -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}')"
```

---

### 2. L·ªói torch.load Security (CVE-2025-32434)

**Tri·ªáu ch·ª©ng:**
```
ValueError: Due to a serious vulnerability issue in `torch.load`
we now require users to upgrade torch to at least v2.6
```

**Nguy√™n nh√¢n:** PyTorch 2.5.1 ch∆∞a ƒë·ªß m·ªõi, transformers y√™u c·∫ßu 2.6+

**Gi·∫£i ph√°p:** Code ƒë√£ ƒë∆∞·ª£c c·∫≠p nh·∫≠t ƒë·ªÉ:
- S·ª≠ d·ª•ng `use_safetensors=False` khi c·∫ßn
- T·ª± ƒë·ªông fallback gi·ªØa safetensors v√† PyTorch format
- B·ªè qua c·∫£nh b√°o v·ªõi `HF_HUB_DISABLE_SAFETENSORS_LOAD_WARNING`

---

### 3. L·ªói Hugging Face 403 Forbidden (Discussions)

**Tri·ªáu ch·ª©ng:**
```
403 Forbidden: Discussions are disabled for this repo.
Cannot access content at: https://huggingface.co/api/models/vinai/PhoWhisper-large/discussions
```

**Nguy√™n nh√¢n:** Transformers c·ªë truy c·∫≠p discussions ƒë·ªÉ check safetensors conversion PR

**Gi·∫£i ph√°p:** Code ƒë√£ ƒë∆∞·ª£c c·∫≠p nh·∫≠t v·ªõi:
```python
# T·∫£i v·ªõi safetensors n·∫øu c√≥, kh√¥ng th√¨ d√πng PyTorch format
try:
    model = WhisperForConditionalGeneration.from_pretrained(
        "vinai/PhoWhisper-large",
        use_safetensors=True,
        resume_download=True
    )
except:
    model = WhisperForConditionalGeneration.from_pretrained(
        "vinai/PhoWhisper-large",
        use_safetensors=False  # Fallback
    )
```

---

### 4. L·ªói ModuleNotFoundError: No module named 'librosa'

**Tri·ªáu ch·ª©ng:**
```
ModuleNotFoundError: No module named 'librosa'
```

**Nguy√™n nh√¢n:** Virtual environment ch∆∞a ƒë∆∞·ª£c k√≠ch ho·∫°t

**Gi·∫£i ph√°p:**
```powershell
# K√≠ch ho·∫°t virtual environment
.\s2t\Scripts\Activate.ps1

# Ho·∫∑c ch·∫°y tr·ª±c ti·∫øp v·ªõi Python c·ªßa venv
.\s2t\Scripts\python.exe run_dual_models.py

# C√†i ƒë·∫∑t dependencies
pip install -r requirements.txt
```

---

### 5. L·ªói CUDA Out of Memory

**Tri·ªáu ch·ª©ng:**
```
torch.cuda.OutOfMemoryError: CUDA out of memory
```

**Gi·∫£i ph√°p:**

1. **Gi·∫£m batch size / chunk size:**
```python
# Trong run_dual_models.py, d√≤ng ~205
chunk_duration = 20  # Gi·∫£m t·ª´ 30 xu·ªëng 20
```

2. **D√πng compute_type nh·∫π h∆°n:**
```python
# Whisper
whisper_model = WhisperModel("large-v3", device="cuda", compute_type="int8")

# PhoWhisper - kh√¥ng d√πng half precision
pho_model = WhisperForConditionalGeneration.from_pretrained(
    "vinai/PhoWhisper-large",
    torch_dtype=torch.float32  # Thay v√¨ float16
)
```

3. **Fallback sang CPU:**
```python
device = "cpu"
```

---

### 6. Script Ch·∫°y Ch·∫≠m

**T·ªëi ∆∞u h√≥a:**

1. **B·∫≠t GPU acceleration:**
```powershell
# Ki·ªÉm tra GPU
nvidia-smi
python -c "import torch; print(torch.cuda.is_available())"
```

2. **Gi·∫£m beam_size:**
```python
# Whisper - d√≤ng ~122
beam_size=3  # Gi·∫£m t·ª´ 5 xu·ªëng 3

# PhoWhisper - d√≤ng ~223
num_beams=5  # Gi·∫£m t·ª´ 8 xu·ªëng 5
```

3. **T·∫Øt preprocessing n·∫øu audio ƒë√£ s·∫°ch:**
```python
cleaned_path = AUDIO_PATH  # B·ªè qua preprocessing
preprocessing_time = 0
```

---

## üöÄ Quick Fix Command

N·∫øu g·∫∑p b·∫•t k·ª≥ l·ªói n√†o, ch·∫°y l·ªánh n√†y:

```powershell
# K√≠ch ho·∫°t venv v√† ch·∫°y script
.\s2t\Scripts\Activate.ps1
.\s2t\Scripts\python.exe run_dual_models.py
```

---

## üìû Li√™n H·ªá Support

N·∫øu v·∫´n g·∫∑p l·ªói, h√£y:
1. Copy to√†n b·ªô error message
2. Ch·∫°y `python test_cuda.py` ƒë·ªÉ ki·ªÉm tra h·ªá th·ªëng
3. Ki·ªÉm tra version: `pip list | findstr "torch transformers faster-whisper"`

---

**C·∫≠p nh·∫≠t:** 14/10/2025
