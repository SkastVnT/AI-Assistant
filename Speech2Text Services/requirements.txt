# ============================================================================
# VistralS2T - Vietnamese Speech-to-Text System
# Version: 3.6.0 - Code Restructuring & Modular Architecture
# Python: 3.10.6 (managed by pyenv)
# Branch: VistralS2T
# ============================================================================

# NOTE: If you encounter "resolution-too-deep" errors, use step-by-step installation:
# Run: .\scripts\fix_dependencies.bat
# This will install in correct order: PyTorch → AI Models → Audio → Web UI

# ============= CORE FOUNDATION =============
# PyTorch (install first to avoid conflicts)
torch==2.0.1
torchaudio==2.0.2
numpy==1.24.4

# ============= CORE AI MODELS =============
# Whisper (Global ASR)
faster-whisper==1.0.3

# PhoWhisper (Vietnamese ASR) + Transformers
transformers==4.40.0
accelerate==0.27.2
sentencepiece==0.2.0

# Qwen2.5-1.5B-Instruct (Smart Fusion LLM)
# Uses transformers package above

# Speaker Diarization (UPDATED in v3.5)
pyannote.audio==3.1.1
# Note: Requires HF_TOKEN for model access
# Accept license at: https://huggingface.co/pyannote/speaker-diarization-3.1

# HuggingFace Hub (for model downloads)
huggingface-hub==0.21.4

# ============= VOICE ACTIVITY DETECTION (NEW in v3.5) =============
# Silero VAD loads from torch.hub automatically
# No separate package needed, but requires torch + torchaudio above

# ============= AUDIO PROCESSING =============
librosa==0.10.1
soundfile==0.12.1
scipy==1.11.4
audioread==3.0.1
av>=12.0.0

# TorchCodec (OPTIONAL - for PhoWhisper optimization)
# Requires FFmpeg: run scripts\install_ffmpeg.bat first
# torchcodec==0.1.0

# ============= UTILITIES =============
# Environment variables
python-dotenv==1.0.1

# Progress bars and console output
tqdm==4.66.0
colorama==0.4.6
rich==13.7.0

# System monitoring
psutil==5.9.8

# Web UI (UPDATED in v3.5)
flask==3.0.2
flask-cors==4.0.0
flask-socketio==5.3.6
python-socketio==5.11.1
eventlet==0.35.2

# ============= DEVELOPMENT =============
# Code formatting
black==25.11.0

# Linting
flake8==7.0.0

# Testing
pytest==8.0.0

# Type checking
mypy==1.8.0

# ============= OPTIONAL ENHANCEMENTS =============
# Better audio formats support
pydub==0.25.1
# Better audio formats support
pydub>=0.25.1

# ============================================================================
# INSTALLATION GUIDE
# ============================================================================
# 
# QUICK START (First Time):
# 1. Run setup.bat (creates venv, installs dependencies)
# 2. Edit app/config/.env (add HF_TOKEN if needed)
# 3. Run run.bat (starts transcription)
#
# COMPLETE REBUILD (Fix Issues):
# 1. Run rebuild_project.bat (full system rebuild with pyenv)
# 2. Follow prompts for pyenv 3.10.6 setup
# 3. Docker rebuild included
#
# MANUAL INSTALLATION:
# 1. Install pyenv: https://github.com/pyenv-win/pyenv-win
# 2. Install Python: pyenv install 3.10.6
# 3. Set version: pyenv local 3.10.6; pyenv shell 3.10.6
# 4. Create venv: pyenv exec python -m venv app\s2t
# 5. Activate: .\app\s2t\Scripts\activate
# 6. Install deps: pip install -r requirements.txt
#
# GPU SUPPORT (REQUIRED):
# - NVIDIA GPU with CUDA 11.8
# - Visit https://pytorch.org/get-started/locally/ for torch+CUDA install
# - Minimum 6GB VRAM (8GB+ recommended)
#
# API KEYS (OPTIONAL):
# - HF_TOKEN in .env for gated models (Vistral-7B)
# - Current setup uses FREE models (no API keys required)
#
# ============================================================================
# SYSTEM ARCHITECTURE
# ============================================================================
#
# DUAL-MODEL PIPELINE:
# ┌──────────────┐
# │   Audio      │ (32kHz, preprocessed)
# └──────┬───────┘
#        │
#        ├─────────────────────┬─────────────────────┐
#        ▼                     ▼                     ▼
#  Whisper large-v3    PhoWhisper-large      (30s chunks)
#  (Global ASR)        (Vietnamese ASR)
#        │                     │
#        └─────────┬───────────┘
#                  ▼
#       Qwen2.5-1.5B-Instruct
#       (Smart Fusion LLM)
#                  │
#                  ▼
#        Final Transcript
#   (3-role speaker separation)
#
# OUTPUT STRUCTURE:
# - app/output/raw/        - Individual model outputs
# - app/output/vistral/    - Final fused transcript
# - app/output/dual/       - Processing logs
#
# MODELS:
# - Whisper large-v3: OpenAI/whisper-large-v3 (~3GB)
# - PhoWhisper-large: vinai/PhoWhisper-large (~1.5GB)
# - Qwen2.5-1.5B: Alibaba Qwen/Qwen2.5-1.5B-Instruct (~3GB)
#
# TOTAL STORAGE: ~10GB (models + cache)
# TOTAL VRAM: ~6GB during processing
#
# ============================================================================
# FEATURES
# ============================================================================
#
# ✅ 100% FREE models (no paid APIs)
# ✅ Vietnamese-optimized (PhoWhisper + Qwen fusion)
# ✅ Dual transcription for maximum accuracy
# ✅ Smart fusion (takes best parts from both models)
# ✅ 3-role speaker separation (Hệ thống, Nhân viên, Khách hàng)
# ✅ Context-aware role detection
# ✅ Docker deployment ready
# ✅ Complete rebuild automation (rebuild_project.bat)
# ✅ Health checks (check.py)
#
# ============================================================================
# DOCUMENTATION
# ============================================================================
#
# - README.md         - Main documentation
# - QUICKREF.md       - Quick reference guide
# - VERSION.md        - Version history
# - CONTRIBUTING.md   - Development guide
# - app/docker/README.md - Docker deployment
#
# ============================================================================
# SUPPORT
# ============================================================================
#
# Repository: https://github.com/SkastVnT/Speech2Text
# Branch: VistralS2T
# Issues: https://github.com/SkastVnT/Speech2Text/issues
#
# ============================================================================
