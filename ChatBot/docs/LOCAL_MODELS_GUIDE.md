# üñ•Ô∏è Local Models Setup Guide

## ‚úÖ ƒê√£ t√≠ch h·ª£p 3 Local Models v√†o ChatBot!

### **1. Qwen1.5-1.8B Local** (Nh·ªè g·ªçn - Nhanh)
- **K√≠ch th∆∞·ªõc:** ~3.6GB
- **VRAM:** 2GB (FP16) ho·∫∑c 1GB (8-bit)
- **T·ªëc ƒë·ªô:** ~50 tokens/second (GPU)
- **ƒê·∫∑c ƒëi·ªÉm:** Nh·ªè, nhanh, ƒëa ng√¥n ng·ªØ

### **2. BloomVN-8B Local** (Ti·∫øng Vi·ªát)
- **K√≠ch th∆∞·ªõc:** ~15GB  
- **VRAM:** 8GB (FP16) ho·∫∑c 4GB (8-bit)
- **T·ªëc ƒë·ªô:** ~20 tokens/second (GPU)
- **ƒê·∫∑c ƒëi·ªÉm:** Model ti·∫øng Vi·ªát native, hi·ªÉu vƒÉn h√≥a VN

### **3. Qwen2.5-14B Local** ‚≠ê (M·∫°nh nh·∫•t)
- **K√≠ch th∆∞·ªõc:** ~28GB
- **VRAM:** 14GB (FP16) ho·∫∑c **7GB (8-bit)** ‚úÖ  
- **T·ªëc ƒë·ªô:** ~15 tokens/second (GPU)
- **ƒê·∫∑c ƒëi·ªÉm:**
  - Ch·∫•t l∆∞·ª£ng g·∫ßn GPT-4
  - Code generation xu·∫•t s·∫Øc
  - 128K context window
  - Multilingual (EN, ZH, VI, ...)

---

## üöÄ H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng:

### B∆∞·ªõc 1: C√†i dependencies

```powershell
cd i:\AI-Assistant\ChatBot
pip install torch transformers accelerate sentencepiece bitsandbytes
```

**L∆∞u √Ω:**
- N·∫øu c√≥ GPU: C√†i `torch` v·ªõi CUDA support
- N·∫øu ch·ªâ CPU: C√†i `torch` CPU version

### B∆∞·ªõc 2: Ki·ªÉm tra models ƒë√£ c√≥

Models ƒë√£ ƒë∆∞·ª£c download t·∫°i:
```
ChatBot/models/
‚îú‚îÄ‚îÄ BloomVN-8B-chat/           ‚úÖ
‚îú‚îÄ‚îÄ Qwen1.5-1.8B-Chat/         ‚úÖ
‚îî‚îÄ‚îÄ Qwen2.5-14B-Instruct/      ‚úÖ
```

### B∆∞·ªõc 3: Kh·ªüi ƒë·ªông ChatBot

```powershell
cd i:\AI-Assistant\ChatBot
python app.py
```

### B∆∞·ªõc 4: S·ª≠ d·ª•ng

1. M·ªü tr√¨nh duy·ªát: `http://127.0.0.1:5000`
2. Dropdown "Ch·ªçn Model"
3. Ch·ªçn m·ªôt trong 3 local models:
   - üñ•Ô∏è Qwen1.5-1.8B Local (nhanh nh·∫•t)
   - üñ•Ô∏è BloomVN-8B Local (ti·∫øng Vi·ªát)
   - üñ•Ô∏è Qwen2.5-14B Local ‚≠ê (ch·∫•t l∆∞·ª£ng cao nh·∫•t)
4. Chat b√¨nh th∆∞·ªùng!

---

## üíª Y√™u c·∫ßu h·ªá th·ªëng:

### GPU (Khuy·∫øn ngh·ªã)

| Model | VRAM FP16 | VRAM 8-bit | RAM |
|-------|-----------|------------|-----|
| Qwen1.5-1.8B | 2GB | 1GB | 8GB |
| BloomVN-8B | 8GB | 4GB | 16GB |
| Qwen2.5-14B | 14GB | **7GB** ‚úÖ | 16GB |

**GPU khuy·∫øn ngh·ªã:**
- RTX 3060 (12GB): Ch·∫°y t·∫•t c·∫£ v·ªõi 8-bit
- RTX 3060 Ti (8GB): Ch·∫°y BloomVN ho·∫∑c Qwen1.5
- RTX 3080/3090 (10-24GB): Ch·∫°y t·∫•t c·∫£ m∆∞·ª£t m√†

### CPU (Kh√¥ng c√≥ GPU)

| Model | RAM | T·ªëc ƒë·ªô |
|-------|-----|--------|
| Qwen1.5-1.8B | 8GB | ~5 tokens/s |
| BloomVN-8B | 16GB | ~2 tokens/s |
| Qwen2.5-14B | 32GB | ~1 token/s |

**L∆∞u √Ω:** CPU mode ch·∫≠m h∆°n GPU 10-50x!

---

## üéØ Khi n√†o d√πng model n√†o?

### **Qwen1.5-1.8B Local** - T·ªët cho:
‚úÖ M√°y y·∫øu (< 8GB VRAM)
‚úÖ Chat nhanh, ƒë∆°n gi·∫£n
‚úÖ Test, development
‚ùå Code ph·ª©c t·∫°p
‚ùå Reasoning cao

### **BloomVN-8B Local** - T·ªët cho:
‚úÖ Chat ti·∫øng Vi·ªát t·ª± nhi√™n
‚úÖ Hi·ªÉu vƒÉn h√≥a, ng·ªØ c·∫£nh VN
‚úÖ T√¢m l√Ω, t∆∞ v·∫•n ƒë·ªùi s·ªëng
‚ùå Code generation
‚ùå English content

### **Qwen2.5-14B Local** ‚≠ê - T·ªët cho:
‚úÖ **M·ªåI TASK** (t·ªët nh·∫•t)
‚úÖ Code generation (ngang GPT-4)
‚úÖ Complex reasoning
‚úÖ Long context (128K)
‚úÖ Multilingual
‚úÖ Production use
‚ö†Ô∏è C·∫ßn 7-14GB VRAM

---

## üî• T·ªëi ∆∞u VRAM:

### N·∫øu thi·∫øu VRAM:

**1. Enable 8-bit quantization (T·ª± ƒë·ªông)**
- Qwen2.5-14B: 14GB ‚Üí **7GB** ‚úÖ
- BloomVN-8B: 8GB ‚Üí **4GB** ‚úÖ
- Quality ch·ªâ gi·∫£m ~2-3%

**2. Gi·∫£m max_tokens**
- Normal: 1000 tokens
- Deep Thinking: 2000 tokens
- C√≥ th·ªÉ gi·∫£m xu·ªëng 500 n·∫øu c·∫ßn

**3. Unload models kh√¥ng d√πng**
```javascript
// Call API to unload
fetch('/api/unload-model', {
    method: 'POST',
    body: JSON.stringify({model_key: 'qwen2.5'})
})
```

**4. Ch·ªâ load 1 model t·∫°i 1 th·ªùi ƒëi·ªÉm**
- Models s·∫Ω lazy load khi c·∫ßn
- T·ª± ƒë·ªông cache khi ƒë√£ load

---

## üìä So s√°nh v·ªõi Cloud API:

| Feature | Local | Cloud |
|---------|-------|-------|
| **Chi ph√≠** | FREE (0ƒë) | $0.04-0.15/1M tokens |
| **Internet** | Kh√¥ng c·∫ßn | B·∫Øt bu·ªôc |
| **Privacy** | 100% private | ƒêi qua server |
| **T·ªëc ƒë·ªô** | Ph·ª• thu·ªôc GPU | Nhanh & ·ªïn ƒë·ªãnh |
| **Quality** | Qwen2.5 ‚âà GPT-4 | GPT-4o best |
| **Gi·ªõi h·∫°n** | Kh√¥ng gi·ªõi h·∫°n | Rate limits |
| **Setup** | Ph·ª©c t·∫°p | D·ªÖ (ch·ªâ c·∫ßn API key) |

---

## üêõ Troubleshooting:

### ‚ùå "Out of memory" error
**Gi·∫£i ph√°p:**
1. D√πng model nh·ªè h∆°n (Qwen1.5 thay v√¨ Qwen2.5)
2. Close c√°c ch∆∞∆°ng tr√¨nh kh√°c
3. Enable 8-bit quantization (t·ª± ƒë·ªông)
4. Restart ChatBot

### ‚ùå "Model not found" error  
**Gi·∫£i ph√°p:**
1. Ki·ªÉm tra path: `ChatBot/models/Qwen2.5-14B-Instruct/`
2. Verify files exist (model-*.safetensors)
3. Re-download model n·∫øu thi·∫øu files

### ‚ùå Response r·∫•t ch·∫≠m
**Gi·∫£i ph√°p:**
1. Check GPU usage (Task Manager)
2. D√πng model nh·ªè h∆°n
3. N·∫øu CPU: Ch·∫•p nh·∫≠n ch·∫≠m ho·∫∑c d√πng Cloud API

### ‚ùå "CUDA out of memory"
**Gi·∫£i ph√°p:**
1. Close Stable Diffusion WebUI (gi·∫£i ph√≥ng VRAM)
2. D√πng 8-bit quantization
3. D√πng model nh·ªè h∆°n

### ‚ùå Import error "torch not found"
**Gi·∫£i ph√°p:**
```powershell
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

---

## üéì Best Practices:

### 1. **Ch·ªçn model ph√π h·ª£p**
- M√°y y·∫øu: Qwen1.5
- Ti·∫øng Vi·ªát: BloomVN
- Production: Qwen2.5 ‚≠ê

### 2. **Qu·∫£n l√Ω memory**
- Ch·ªâ load model ƒëang d√πng
- Unload model c≈© tr∆∞·ªõc khi load m·ªõi
- Close app kh√¥ng c·∫ßn thi·∫øt

### 3. **Optimize cho t·ªëc ƒë·ªô**
- D√πng GPU n·∫øu c√≥
- Enable 8-bit quantization
- Gi·∫£m max_tokens n·∫øu kh√¥ng c·∫ßn

### 4. **Backup v√† update**
- Backup models folder ƒë·ªãnh k·ª≥
- Check updates tr√™n Hugging Face
- Test model m·ªõi tr∆∞·ªõc khi replace

---

## üìà Performance Tips:

### GPU Optimization:
```python
# Already implemented in code:
- device_map="auto"          # Auto GPU selection
- load_in_8bit=True          # 8-bit quantization
- torch_dtype=torch.float16  # FP16 precision
```

### CPU Optimization:
```python
# For CPU mode:
- Use smaller model (Qwen1.5)
- Reduce max_tokens (500 instead of 1000)
- Lower temperature (0.5 instead of 0.7)
```

---

## üîó Resources:

- **Qwen2.5-14B:** https://huggingface.co/Qwen/Qwen2.5-14B-Instruct
- **Qwen1.5-1.8B:** https://huggingface.co/Qwen/Qwen1.5-1.8B-Chat
- **BloomVN-8B:** https://huggingface.co/BlossomsAI/BloomVN-8B-chat
- **Transformers Docs:** https://huggingface.co/docs/transformers

---

## ‚úÖ Checklist:

- [ ] C√†i dependencies: `torch`, `transformers`, `accelerate`
- [ ] Ki·ªÉm tra models ƒë√£ t·∫£i: `models/` folder
- [ ] Kh·ªüi ƒë·ªông ChatBot: `python app.py`
- [ ] Ch·ªçn local model trong dropdown
- [ ] Test chat v·ªõi t·ª´ng model
- [ ] Verify VRAM usage (Task Manager ‚Üí GPU)
- [ ] Compare quality vs cloud models

---

**Enjoy 100% FREE local AI!** üéâ

**No internet. No API keys. No limits. Just pure AI power on your machine!** üí™
