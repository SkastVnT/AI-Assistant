# ChatBot Service - AI Assistant v2.6

Advanced multi-model intelligent chatbot with **Deep Thinking (o1-style)**, ChatGPT-inspired UI, file analysis, and modern features.

<details>
<summary><strong>ğŸŒŸ Latest Updates (v2.6)</strong></summary>

### ğŸ§  Deep Thinking Feature (OpenAI o1-style)

- **Visible Thinking Process**: See AI's reasoning steps in real-time
- **Collapsible Sections**: Click to expand/collapse thinking details
- **Auto-enabled for Files**: Automatically activates when analyzing uploaded documents
- **Smart Analysis**: 6-step reasoning process for comprehensive responses
  1. Reading and parsing files
  2. Extracting key information
  3. Identifying main topics
  4. Analyzing content depth
  5. Cross-referencing information
  6. Formulating comprehensive response

### ğŸ’¬ ChatGPT-Style Message Actions

- **Action Buttons**: Copy, Like/Dislike, Regenerate, Edit, More options
- **Hover-to-Show**: Smooth animations for clean interface
- **Message Versioning**: Navigate between multiple response versions (â—€ 1/2 â–¶)
- **Edit & Regenerate**: Click edit â†’ modify message â†’ get new response
- **Copy to Clipboard**: One-click copy with visual confirmation

### ğŸ“ Enhanced File Upload (50MB Support)

- **Upload Button**: Click "ğŸ“ Upload Files" to select documents
- **Drag & Drop**: Paste files directly (Ctrl+V)
- **Large File Support**: Up to 50MB per file
- **Smart Context**: Files automatically included in conversation
- **Chat-based Errors**: No more annoying popups - errors shown in chat
- **User-initiated Analysis**: Upload â†’ Ask questions â†’ Get insights

### ğŸ“ Markdown Code Blocks

- **Proper Formatting**: AI uses ` ` `language` syntax for code
- **Syntax Highlighting**: Python, JavaScript, SQL, etc.
- **Inline Code**: Variables and functions with \`backticks\`
- **All Modes Supported**: Works in Casual, Programming, Lifestyle, Psychological modes

</details>

<details>
<summary><strong>ğŸŒŸ Core Features</strong></summary>

### ğŸ¤– AI Capabilities

- **Multi-Model Support**: OpenAI GPT-4, Google Gemini, DeepSeek, Local Qwen models
- **Image Generation**: Integration with Stable Diffusion WebUI API
  - Text-to-Image (txt2img)
  - Image-to-Image (img2img) with LoRA and VAE support
  - Advanced parameters control (Steps, CFG Scale, Samplers)
- **Smart File Analysis**: Automatic analysis of uploaded files
  - Support for code files (.py, .js, .html, .css, .json)
  - Document processing (.pdf, .doc, .docx)
  - Image recognition
  - Auto-generated insights without user prompting

### ğŸ’¾ Data Management

- **Memory System**: Persistent conversation history with image storage
- **Message Versioning**: Track multiple versions of AI responses
- **Session-based Files**: Files attached per conversation
- **Smart Storage**: Progress bar with auto-cleanup (keeps 5 recent chats)

### âš¡ User Experience

- **Stop Generation**: Interrupt AI mid-response and keep partial output
- **Full-Screen Layout**: ChatGPT-like interface utilizing entire viewport
- **Message Editing**: Edit and regenerate responses
- **Export**: PDF export for conversations with images
- **Modern UI**: Responsive design with dark mode support

</details>

<details>
<summary><strong>ğŸ“‹ Requirements & Quick Start</strong></summary>

## Requirements

- Python 3.10.6
- NVIDIA GPU with CUDA 11.8 (for local models)
- 8GB+ RAM (16GB recommended for local models)
- Stable Diffusion WebUI running (for image generation)

## ğŸš€ Quick Start

### 1. Setup Virtual Environment

```bash
# Create virtual environment
python -m venv venv_chatbot

# Activate (Windows)
.\venv_chatbot\Scripts\activate

# Activate (Linux/Mac)
source venv_chatbot/bin/activate
```

### 2. Install Dependencies

```bash
# Install PyTorch with CUDA (for GPU)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# Install other dependencies
pip install -r requirements.txt
```

### 3. Configure Environment

```bash
# Copy example environment file
copy .env.example .env

# Edit .env and add your API keys:
# - OPENAI_API_KEY (for GPT-4)
# - GOOGLE_API_KEY (for Gemini)
# - SD_API_URL (Stable Diffusion API, default: http://127.0.0.1:7860)
```

### 4. Run Application

```bash
python app.py
```

Access at: <http://localhost:5000>

</details>

<details>
<summary><strong>ğŸ¨ Image Generation Setup</strong></summary>

1. Start Stable Diffusion WebUI with API enabled:
   ```bash
   cd ../stable-diffusion-webui
   python webui.py --api
   ```

2. Image generation features:
   - **Text-to-Image**: Generate images from text prompts
   - **Image-to-Image**: Transform existing images
   - **LoRA Models**: Apply style transformations
   - **VAE**: Use custom VAE models
   - **Advanced Settings**: Steps, CFG Scale, Sampling methods

</details>

<details>
<summary><strong>ğŸ“ Project Structure</strong></summary>

```
ChatBot/
â”œâ”€â”€ app.py                      # Main Flask application
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ .env.example               # Environment variables template
â”œâ”€â”€ README.md                  # This file
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html             # Main UI (modular, 509 lines)
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ css/
â”‚   â”‚   â””â”€â”€ style.css          # Custom styles (~2200 lines)
â”‚   â””â”€â”€ js/
â”‚       â”œâ”€â”€ main.js            # Main app controller
â”‚       â””â”€â”€ modules/           # ES6 Modules
â”‚           â”œâ”€â”€ chat-manager.js      # Session management
â”‚           â”œâ”€â”€ api-service.js       # API communications
â”‚           â”œâ”€â”€ ui-utils.js          # UI utilities
â”‚           â”œâ”€â”€ message-renderer.js  # Message rendering
â”‚           â”œâ”€â”€ file-handler.js      # File processing
â”‚           â”œâ”€â”€ memory-manager.js    # Memory features
â”‚           â”œâ”€â”€ image-gen.js         # Image generation
â”‚           â””â”€â”€ export-handler.js    # PDF export
â”œâ”€â”€ src/
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ local_model_loader.py  # Local model management
â”‚       â””â”€â”€ sd_client.py           # Stable Diffusion API client
â”œâ”€â”€ models/
â”‚   â””â”€â”€ Qwen1.5-1.8B-Chat/        # Local LLM model
â”œâ”€â”€ Storage/
â”‚   â””â”€â”€ Image_Gen/                 # Generated images
â””â”€â”€ data/
    â””â”€â”€ memory/                    # Conversation memories
```

</details>

<details>
<summary><strong>ğŸ”§ Configuration & Setup</strong></summary>

## Configuration

### Environment Variables (.env)

```env
# API Keys
OPENAI_API_KEY=your_openai_key
GOOGLE_API_KEY=your_google_key

# Stable Diffusion
SD_API_URL=http://127.0.0.1:7860

# Server
FLASK_PORT=5000
FLASK_DEBUG=False
```

### Model Selection

- **GPT-4**: Best quality, requires API key
- **Gemini**: Fast and capable, requires API key
- **Qwen (Local)**: Free, runs locally, requires GPU

</details>

<details>
<summary><strong>ğŸ“– Usage Guide</strong></summary>

## Usage Guide

### Basic Chat

1. Select a model from the dropdown
2. Choose context mode (Casual, Psychological, Lifestyle, Programming)
3. Type your message
4. Click Send or press Enter
5. **NEW:** Click "â¹ï¸ Dá»«ng láº¡i" to stop AI mid-generation

### File Upload & Analysis

1. Click "ğŸ“ Upload Files" button
2. Select files (up to 50MB each)
3. Files appear in chat with confirmation message
4. **Type your question** about the file
5. **Deep Thinking auto-enables** for better analysis
6. See thinking process â†’ Get comprehensive answer

**Supported files:**

- Code: `.py`, `.js`, `.html`, `.css`, `.json`
- Documents: `.pdf`, `.doc`, `.docx`, `.txt`, `.xlsx`, `.csv`
- Images: `.jpg`, `.png`, `.gif`, `.webp`

**Example workflow:**
```
1. Upload: contract.pdf (127KB)
   âœ… ÄÃ£ táº£i lÃªn 1 file. Báº¡n cÃ³ thá»ƒ há»i tÃ´i vá» ná»™i dung file bÃ¢y giá»!

2. You ask: "TÃ³m táº¯t file nÃ y"
   
3. AI shows thinking:
   ğŸ’¡ Thought process â–¼
   1. Äá»c vÃ  phÃ¢n tÃ­ch file Ä‘Ã­nh kÃ¨m...
   2. TrÃ­ch xuáº¥t thÃ´ng tin vÃ  cáº¥u trÃºc chÃ­nh...
   3. XÃ¡c Ä‘á»‹nh cÃ¡c chá»§ Ä‘á» vÃ  ná»™i dung chÃ­nh...
   
4. AI provides detailed summary
```

### Image Generation

1. Click "ğŸ¨ Táº¡o áº£nh" button
2. Choose tab:
   - **Text2Img**: Generate from text prompt
   - **Img2Img**: Transform existing image
3. Configure parameters (optional):
   - Steps: 20-50 (higher = better quality)
   - CFG Scale: 7-12 (higher = follow prompt more)
   - Select LoRA or VAE models
4. Click "Generate"
5. Copy to chat or download

### Memory Features

1. Click "ğŸ§  AI há»c táº­p" to open memory panel
2. Select memories to activate for current chat
3. Save current conversation as memory
4. AI will use activated memories as context

### Storage Management

- **Progress bar** shows storage usage (0-200MB)
- Status indicators:
  - ğŸ’š Green (0-50%): Good
  - ğŸŸ¡ Yellow (50-80%): Warning
  - ğŸ”´ Red (80-100%): Full
- Click "ğŸ—‘ï¸ Dá»n dáº¹p" to auto-cleanup (keeps 5 recent chats)

### Export to PDF

1. Click "ğŸ“¥ Táº£i chat" button
2. PDF includes messages, images, and metadata
3. Saved automatically to downloads

## ğŸ› Troubleshooting

### Local Model Issues

```bash
# If Qwen model fails to load:
1. Check GPU memory (requires ~4GB VRAM)
2. Verify CUDA installation: nvidia-smi
3. Try CPU mode (slower): Edit app.py, set device='cpu'
```

### Image Generation Issues

```bash
# If SD API connection fails:
1. Verify SD WebUI is running with --api flag
2. Check SD_API_URL in .env
3. Test connection: http://127.0.0.1:7860/docs
```

### Dependencies Issues

```bash
# If torch installation fails:
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# If bitsandbytes fails on Windows:
# It's optional, comment out in requirements.txt
```

## ğŸ“š Documentation

### Core Features
- **[NEW! v2.0 Features](docs/NEW_FEATURES_v2.0.md)** - Complete guide to latest features
- [Image Generation Guide](docs/IMAGE_GENERATION_TOOL_GUIDE.md)
- [LoRA & VAE Guide](docs/LORA_VAE_GUIDE.md)
- [Memory Features](docs/MEMORY_WITH_IMAGES_FEATURE.md)
- [UI Improvements](docs/UI_IMPROVEMENTS.md)

### Technical Documentation
- [Module Architecture](docs/NEW_FEATURES_v2.0.md#71-module-architecture)
- [File Upload System](docs/NEW_FEATURES_v2.0.md#5-file-upload-revolution)
- [Storage Management](docs/NEW_FEATURES_v2.0.md#73-storage-management)
- [Performance Optimizations](docs/NEW_FEATURES_v2.0.md#8-performance-optimizations)

</details>

<details>
<summary><strong>ğŸ”„ Changelog</strong></summary>

### Version 2.6.0 (December 1, 2025) ğŸ¨

**Production Refinements & Documentation**

- ğŸ“š **Complete Documentation**: Comprehensive README with all v2.5 features documented
- ğŸ¨ **UI Polish**: Refined Deep Thinking animations and transitions
- ğŸ› **Bug Fixes**: Event listener stability improvements
- ğŸ“Š **Performance**: Optimized file upload handling
- ğŸ”§ **Code Quality**: Better error handling and logging
- ğŸ“– **User Guides**: Enhanced troubleshooting and setup instructions

### Version 2.5.0 (November 25, 2025) ğŸ§ 

**Deep Thinking & UX Enhancements**

- âœ¨ **Deep Thinking (o1-style)**: Visible reasoning process with collapsible sections
- âœ¨ **ChatGPT-Style Actions**: Copy, Like/Dislike, Regenerate, Edit buttons with hover effects
- âœ¨ **Message Versioning**: Navigate response versions with â—€ 1/2 â–¶ controls
- âœ¨ **Enhanced File Upload**: 50MB support, chat-based error messages
- âœ¨ **Smart File Analysis**: Auto-enable Deep Thinking for uploaded documents
- âœ¨ **Markdown Code Blocks**: Proper ` ` `language` syntax in all modes
- ğŸ¨ **Improved UI**: Smooth animations, better visual feedback
- ğŸ› **Fixed**: File upload button, event listeners after refresh, version navigation

### Version 2.0.0 (November 2025) ğŸ‰

**Major UI/UX Overhaul**

- âœ¨ **Full-screen ChatGPT-like layout** - Utilizes entire viewport
- âœ¨ **Stop generation** - Interrupt AI and keep partial responses
- âœ¨ **Message editing** - Edit and regenerate AI responses
- âœ¨ **Fancy storage display** - Progress bar with smart cleanup
- ğŸ¨ **Enhanced UI/UX** - Better visibility, GitHub badge, centered header
- ğŸ› **Fixed timestamp bug** - Chat items no longer "jump" when switching
- ğŸ”§ **Modular architecture** - ES6 modules for better maintainability

### Version 1.8.0

- Added img2img support with LoRA and VAE
- Improved UI with Tailwind CSS
- Enhanced memory system with images
- Added PDF export functionality

### Version 1.5.0

- Added local Qwen model support
- Implemented conversation memory
- Added image generation tool

</details>

<details>
<summary><strong>ğŸ†• What's New Highlights</strong></summary>

## What's New in v2.6?

### Production Ready & Polished

**ğŸ“š Documentation Excellence**
```
âœ… Complete feature documentation
âœ… Troubleshooting guides
âœ… Setup wizards
âœ… Best practices
```

**ğŸ¨ UI Refinements**
```
âœ… Smoother animations
âœ… Better loading states
âœ… Improved error messages
âœ… Visual polish
```

**ğŸ› Stability Improvements**
```
âœ… Event listener fixes
âœ… Better error handling
âœ… Performance optimizations
âœ… Edge case handling
```

## What's New in v2.5?

### Key Highlights

**1. Upload & Forget** ğŸ“
```
Before: Upload â†’ Type question â†’ Wait for response
Now:    Upload â†’ Instant AI analysis appears!
```

**2. Stop When You Want** â¹ï¸
```
AI generating long response...
[Click Stop button]
â†’ Keeps partial response
â†’ Continue conversation from there
```

**3. Beautiful Storage Management** ğŸ’š
```
Old: "ğŸ“Š LÆ°u trá»¯: 5MB / 200MB (2%)"
New: Progress bar with colors + One-click cleanup
```

**4. ChatGPT-like Experience** ğŸš€
- Full-screen layout
- Messages span wider (85% width)
- Better chat item visibility
- Smooth animations
- Dark mode perfected

</details>

## ğŸ“ License & Contributing

Part of AI-Assistant project. See root LICENSE file.

This is a sub-service of AI-Assistant project. For contributions, please refer to the main project repository.

Interested in specific features? Check out:

- [CHANGELOG.md](CHANGELOG.md) - Full version history
- [NEW_FEATURES_v2.0.md](docs/NEW_FEATURES_v2.0.md) - Deep dive into v2.0
- [QUICK_START.md](docs/QUICK_START.md) - 5-minute setup guide

## ğŸ“§ Support

For issues and questions:

- Create an issue in [main repository](https://github.com/SkastVnT/AI-Assistant)
- Check [Troubleshooting](docs/NEW_FEATURES_v2.0.md#111-common-issues)
- Review [Quick Start Guide](docs/QUICK_START.md)

## ğŸ™ Acknowledgments

- OpenAI for GPT models
- Google for Gemini API
- Stability AI for Stable Diffusion
- Alibaba Cloud for Qwen models
- Community contributors

---

**Built with â¤ï¸ by [@SkastVnT](https://github.com/SkastVnT)**
**Star â­ this repo if you find it helpful!**
