# ChatBot Service - AI Assistant v2.0

Advanced multi-model intelligent chatbot with local LLM support, image generation, auto-file analysis, and modern UX inspired by ChatGPT.

## ğŸŒŸ Features

### ğŸ¤– AI Capabilities
- **Multi-Model Support**: OpenAI GPT-4, Google Gemini, DeepSeek, Local Qwen models
- **Image Generation**: Integration with Stable Diffusion WebUI API
  - Text-to-Image (txt2img)
  - Image-to-Image (img2img) with LoRA and VAE support
  - Advanced parameters control (Steps, CFG Scale, Samplers)
- **Smart File Analysis**: Automatic analysis of uploaded files
  - Support for code files (.py, .js, .html, .css, .json)
  - Document processing (.pdf, .doc, .docx)
  - Image recognition
  - Auto-generated insights without user prompting

### ğŸ’¾ Data Management
- **Memory System**: Persistent conversation history with image storage
- **Message Versioning**: Track multiple versions of AI responses
- **Session-based Files**: Files attached per conversation
- **Smart Storage**: Progress bar with auto-cleanup (keeps 5 recent chats)

### âš¡ User Experience
- **Stop Generation**: Interrupt AI mid-response and keep partial output
- **Full-Screen Layout**: ChatGPT-like interface utilizing entire viewport
- **Message Editing**: Edit and regenerate responses
- **Export**: PDF export for conversations with images
- **Modern UI**: Responsive design with dark mode support

## ğŸ“‹ Requirements

- Python 3.10.6
- NVIDIA GPU with CUDA 11.8 (for local models)
- 8GB+ RAM (16GB recommended for local models)
- Stable Diffusion WebUI running (for image generation)

## ğŸš€ Quick Start

### 1. Setup Virtual Environment

```bash
# Create virtual environment
python -m venv venv_chatbot

# Activate (Windows)
.\venv_chatbot\Scripts\activate

# Activate (Linux/Mac)
source venv_chatbot/bin/activate
```

### 2. Install Dependencies

```bash
# Install PyTorch with CUDA (for GPU)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# Install other dependencies
pip install -r requirements.txt
```

### 3. Configure Environment

```bash
# Copy example environment file
copy .env.example .env

# Edit .env and add your API keys:
# - OPENAI_API_KEY (for GPT-4)
# - GOOGLE_API_KEY (for Gemini)
# - SD_API_URL (Stable Diffusion API, default: http://127.0.0.1:7860)
```

### 4. Run Application

```bash
python app.py
```

Access at: http://localhost:5000

## ğŸ¨ Image Generation Setup

1. Start Stable Diffusion WebUI with API enabled:
   ```bash
   cd ../stable-diffusion-webui
   python webui.py --api
   ```

2. Image generation features:
   - **Text-to-Image**: Generate images from text prompts
   - **Image-to-Image**: Transform existing images
   - **LoRA Models**: Apply style transformations
   - **VAE**: Use custom VAE models
   - **Advanced Settings**: Steps, CFG Scale, Sampling methods

## ğŸ“ Project Structure

```
ChatBot/
â”œâ”€â”€ app.py                      # Main Flask application
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ .env.example               # Environment variables template
â”œâ”€â”€ README.md                  # This file
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html             # Main UI (modular, 509 lines)
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ css/
â”‚   â”‚   â””â”€â”€ style.css          # Custom styles (~2200 lines)
â”‚   â””â”€â”€ js/
â”‚       â”œâ”€â”€ main.js            # Main app controller
â”‚       â””â”€â”€ modules/           # ES6 Modules
â”‚           â”œâ”€â”€ chat-manager.js      # Session management
â”‚           â”œâ”€â”€ api-service.js       # API communications
â”‚           â”œâ”€â”€ ui-utils.js          # UI utilities
â”‚           â”œâ”€â”€ message-renderer.js  # Message rendering
â”‚           â”œâ”€â”€ file-handler.js      # File processing
â”‚           â”œâ”€â”€ memory-manager.js    # Memory features
â”‚           â”œâ”€â”€ image-gen.js         # Image generation
â”‚           â””â”€â”€ export-handler.js    # PDF export
â”œâ”€â”€ src/
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ local_model_loader.py  # Local model management
â”‚       â””â”€â”€ sd_client.py           # Stable Diffusion API client
â”œâ”€â”€ models/
â”‚   â””â”€â”€ Qwen1.5-1.8B-Chat/        # Local LLM model
â”œâ”€â”€ Storage/
â”‚   â””â”€â”€ Image_Gen/                 # Generated images
â””â”€â”€ data/
    â””â”€â”€ memory/                    # Conversation memories
```

## ğŸ”§ Configuration

### Environment Variables (.env)

```env
# API Keys
OPENAI_API_KEY=your_openai_key
GOOGLE_API_KEY=your_google_key

# Stable Diffusion
SD_API_URL=http://127.0.0.1:7860

# Server
FLASK_PORT=5000
FLASK_DEBUG=False
```

### Model Selection

- **GPT-4**: Best quality, requires API key
- **Gemini**: Fast and capable, requires API key
- **Qwen (Local)**: Free, runs locally, requires GPU

## ğŸ“– Usage Guide

### Basic Chat

1. Select a model from the dropdown
2. Choose context mode (Casual, Psychological, Lifestyle, Programming)
3. Type your message
4. Click Send or press Enter
5. **NEW:** Click "â¹ï¸ Dá»«ng láº¡i" to stop AI mid-generation

### File Upload & Auto-Analysis

1. Click "ğŸ“ Upload Files" or paste (Ctrl+V)
2. **Files appear directly in chat** (not in input area)
3. **AI automatically analyzes** - no need to type anything!
4. Receive detailed analysis:
   - Content summary
   - Issue detection
   - Recommendations
   - Q&A responses

**Supported files:**
- Code: `.py`, `.js`, `.html`, `.css`, `.json`
- Documents: `.pdf`, `.doc`, `.docx`, `.txt`
- Images: `.jpg`, `.png`, `.gif`, `.webp`

### Image Generation

1. Click "ğŸ¨ Táº¡o áº£nh" button
2. Choose tab:
   - **Text2Img**: Generate from text prompt
   - **Img2Img**: Transform existing image
3. Configure parameters (optional):
   - Steps: 20-50 (higher = better quality)
   - CFG Scale: 7-12 (higher = follow prompt more)
   - Select LoRA or VAE models
4. Click "Generate"
5. Copy to chat or download

### Memory Features

1. Click "ğŸ§  AI há»c táº­p" to open memory panel
2. Select memories to activate for current chat
3. Save current conversation as memory
4. AI will use activated memories as context

### Storage Management

- **Progress bar** shows storage usage (0-200MB)
- Status indicators:
  - ğŸ’š Green (0-50%): Good
  - ğŸŸ¡ Yellow (50-80%): Warning
  - ğŸ”´ Red (80-100%): Full
- Click "ğŸ—‘ï¸ Dá»n dáº¹p" to auto-cleanup (keeps 5 recent chats)

### Export to PDF

1. Click "ğŸ“¥ Táº£i chat" button
2. PDF includes messages, images, and metadata
3. Saved automatically to downloads

## ğŸ› Troubleshooting

### Local Model Issues

```bash
# If Qwen model fails to load:
1. Check GPU memory (requires ~4GB VRAM)
2. Verify CUDA installation: nvidia-smi
3. Try CPU mode (slower): Edit app.py, set device='cpu'
```

### Image Generation Issues

```bash
# If SD API connection fails:
1. Verify SD WebUI is running with --api flag
2. Check SD_API_URL in .env
3. Test connection: http://127.0.0.1:7860/docs
```

### Dependencies Issues

```bash
# If torch installation fails:
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# If bitsandbytes fails on Windows:
# It's optional, comment out in requirements.txt
```

## ğŸ“š Documentation

### Core Features
- **[NEW! v2.0 Features](docs/NEW_FEATURES_v2.0.md)** - Complete guide to latest features
- [Image Generation Guide](docs/IMAGE_GENERATION_TOOL_GUIDE.md)
- [LoRA & VAE Guide](docs/LORA_VAE_GUIDE.md)
- [Memory Features](docs/MEMORY_WITH_IMAGES_FEATURE.md)
- [UI Improvements](docs/UI_IMPROVEMENTS.md)

### Technical Documentation
- [Module Architecture](docs/NEW_FEATURES_v2.0.md#71-module-architecture)
- [File Upload System](docs/NEW_FEATURES_v2.0.md#5-file-upload-revolution)
- [Storage Management](docs/NEW_FEATURES_v2.0.md#73-storage-management)
- [Performance Optimizations](docs/NEW_FEATURES_v2.0.md#8-performance-optimizations)

## ğŸ”„ Updates

### Version 2.0.0 (November 2025) ğŸ‰
- âœ¨ **Full-screen ChatGPT-like layout** - Utilizes entire viewport
- âœ¨ **Auto-file analysis** - Upload and get instant AI insights
- âœ¨ **Stop generation** - Interrupt AI and keep partial responses
- âœ¨ **Message versioning** - Track multiple response versions
- âœ¨ **Fancy storage display** - Progress bar with smart cleanup
- ğŸ¨ **Enhanced UI/UX** - Better visibility, GitHub badge, centered header
- ğŸ› **Fixed timestamp bug** - Chat items no longer "jump" when switching
- ğŸ”§ **Modular architecture** - ES6 modules for better maintainability

### Version 1.8.0
- Added img2img support with LoRA and VAE
- Improved UI with Tailwind CSS
- Enhanced memory system with images
- Added PDF export functionality

### Version 1.5.0
- Added local Qwen model support
- Implemented conversation memory
- Added image generation tool

## ğŸ†• What's New in v2.0?

### Key Highlights

**1. Upload & Forget** ğŸ“
```
Before: Upload â†’ Type question â†’ Wait for response
Now:    Upload â†’ Instant AI analysis appears!
```

**2. Stop When You Want** â¹ï¸
```
AI generating long response...
[Click Stop button]
â†’ Keeps partial response
â†’ Continue conversation from there
```

**3. Beautiful Storage Management** ğŸ’š
```
Old: "ğŸ“Š LÆ°u trá»¯: 5MB / 200MB (2%)"
New: Progress bar with colors + One-click cleanup
```

**4. ChatGPT-like Experience** ğŸš€
- Full-screen layout
- Messages span wider (85% width)
- Better chat item visibility
- Smooth animations
- Dark mode perfected

## ğŸ“ License

Part of AI-Assistant project. See root LICENSE file.

## ğŸ¤ Contributing

This is a sub-service of AI-Assistant project. For contributions, please refer to the main project repository.

Interested in specific features? Check out:
- [CHANGELOG.md](CHANGELOG.md) - Full version history
- [NEW_FEATURES_v2.0.md](docs/NEW_FEATURES_v2.0.md) - Deep dive into v2.0
- [QUICK_START.md](docs/QUICK_START.md) - 5-minute setup guide

## ğŸ“§ Support

For issues and questions:
- Create an issue in [main repository](https://github.com/SkastVnT/AI-Assistant)
- Check [Troubleshooting](docs/NEW_FEATURES_v2.0.md#111-common-issues)
- Review [Quick Start Guide](docs/QUICK_START.md)

## ğŸ™ Acknowledgments

- OpenAI for GPT models
- Google for Gemini API
- Stability AI for Stable Diffusion
- Alibaba Cloud for Qwen models
- Community contributors

---

**Built with â¤ï¸ by [@SkastVnT](https://github.com/SkastVnT)**

**Star â­ this repo if you find it helpful!**
