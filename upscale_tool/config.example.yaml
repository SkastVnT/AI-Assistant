# Config example for upscale tool with CUDA/GPU optimizations
# Copy this file to config.yaml and modify as needed

upscaler:
  default_model: RealESRGAN_x4plus  # RealESRGAN_x4plus | RealESRGAN_x4plus_anime_6B | RealESRNet_x4plus | realesr-general-x4v3
  default_scale: 4
  device: auto  # auto (detect best), cuda, cpu, cuda:0, cuda:1 (for multi-GPU)
  gpu_id: 0  # GPU device ID (0, 1, 2, ...) for multi-GPU systems

models:
  download_auto: true
  model_dir: ./models

processing:
  tile_size: 400      # Processing tile size (128-2048). Larger = faster but more VRAM
                      # Recommended: 256 (4GB), 512 (8GB), 1024 (12GB+)
  tile_pad: 10
  pre_pad: 0
  half_precision: true  # FP16 for 2x faster inference (requires GPU compute >= 7.0)
  auto_tile_size: true  # Auto-adjust tile size based on available GPU memory
  
  # CUDA optimizations
  cudnn_benchmark: true  # Enable cuDNN auto-tuner
  tf32_matmul: true     # Enable TF32 on Ampere GPUs (RTX 30xx+)
  clear_cache: true     # Clear GPU cache between batches

output:
  format: png  # png, jpg, webp
  quality: 95  # for jpg (1-100)

# Performance Tips:
# - RTX 4090/4080 (24GB/16GB): tile_size=2048, half_precision=true
# - RTX 3090/3080 (24GB/10GB): tile_size=1024, half_precision=true
# - RTX 3060 (12GB): tile_size=768, half_precision=true
# - RTX 3050/2060 (8GB): tile_size=512, half_precision=true
# - GTX 1660 (6GB): tile_size=384, half_precision=false
# - Low VRAM (<4GB): tile_size=256, half_precision=false, auto_tile_size=true
# - CPU mode: device=cpu, tile_size=256, half_precision=false

