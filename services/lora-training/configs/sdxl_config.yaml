# SDXL LoRA Training Configuration
# For high-resolution training (1024x1024)

model:
  pretrained_model_name_or_path: "stabilityai/stable-diffusion-xl-base-1.0"
  revision: null

lora:
  rank: 32
  alpha: 64
  dropout: 0.0
  target_modules:
    - "to_q"
    - "to_k"
    - "to_v"
    - "to_out.0"
    - "ff.net.0.proj"
    - "ff.net.2"

dataset:
  train_data_dir: "data/train"
  val_data_dir: null
  resolution: 1024  # SDXL native resolution
  center_crop: true
  random_flip: true
  caption_extension: ".txt"

training:
  num_train_epochs: 10
  train_batch_size: 1  # SDXL requires more memory
  gradient_accumulation_steps: 8
  
  optimizer: "adamw"
  learning_rate: 8.0e-5
  weight_decay: 0.01
  max_grad_norm: 1.0
  
  lr_scheduler: "cosine"
  lr_warmup_steps: 150
  
  validation_epochs: 2
  save_steps: 2
  
  output_dir: "outputs/lora_models_sdxl"
  checkpoint_dir: "outputs/checkpoints_sdxl"
  dataloader_num_workers: 4
  
  mixed_precision: "bf16"  # BF16 recommended for SDXL
  gradient_checkpointing: true

logging:
  log_dir: "outputs/logs"
  logging_steps: 10
  generate_samples: true
  sample_steps: 150
  num_samples: 4
  sample_prompts:
    - "a photo of sks person, high quality, detailed"
    - "portrait of sks person, professional lighting"
    - "sks person in cinematic scene, 4k"
    - "sks person, masterpiece, best quality"

advanced:
  noise_offset: 0.05
  snr_gamma: 5.0
  use_ema: false
  enable_xformers: true
  train_text_encoder: false
  color_jitter: false
  random_rotation: false
  cache_latents: false
