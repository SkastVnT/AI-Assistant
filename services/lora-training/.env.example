# Example .env file for train_LoRA_tool
# Copy this to .env and fill in your values

# ====================================
# Gemini AI Configuration (NEW in v2.3)
# ====================================

# Get your API key from: https://aistudio.google.com/app/apikey
GEMINI_API_KEY=your-gemini-api-key-here

# Optional: Gemini model to use (default: gemini-2.0-flash-exp)
# GEMINI_MODEL=gemini-2.0-flash-exp

# ====================================
# HuggingFace Configuration
# ====================================

# HuggingFace token for downloading models
# Get from: https://huggingface.co/settings/tokens
HF_TOKEN=your-huggingface-token-here

# Optional: HuggingFace cache directory
# HF_HOME=./models/huggingface

# ====================================
# WandB Configuration (Optional)
# ====================================

# Weights & Biases for training monitoring
# Get from: https://wandb.ai/authorize
# WANDB_API_KEY=your-wandb-key-here
# WANDB_PROJECT=lora-training
# WANDB_ENTITY=your-username

# ====================================
# Training Paths (Optional)
# ====================================

# Default paths (can override in config files)
# TRAIN_DATA_DIR=./data/train
# OUTPUT_DIR=./output
# MODELS_DIR=./models

# ====================================
# Advanced Settings (Optional)
# ====================================

# CUDA settings
# CUDA_VISIBLE_DEVICES=0
# PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512

# Mixed precision
# MIXED_PRECISION=fp16

# Number of workers for data loading
# NUM_WORKERS=4
