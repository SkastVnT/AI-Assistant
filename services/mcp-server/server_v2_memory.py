"""
AI-Assistant MCP Server V2.0 - WITH PERSISTENT MEMORY
=======================================================
Káº¿t há»£p tÃ­nh nÄƒng cá»§a claude-mem vÃ  MCP Server:
  âœ… Real-time project access (Tools)
  âœ… Persistent memory across sessions (Memory System)
  âœ… AI-powered observations & summaries
  âœ… Full-text search qua history
  âœ… Web UI Ä‘á»ƒ xem memory

Sá»­ dá»¥ng FastMCP SDK (miá»…n phÃ­, mÃ£ nguá»“n má»Ÿ).
"""

import os
import json
import sqlite3
from pathlib import Path
from typing import Any, Dict, List, Optional
from datetime import datetime
import time
import logging

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

try:
    from mcp.server.fastmcp import FastMCP
except ImportError:
    print("ERROR: FastMCP khÃ´ng Ä‘Æ°á»£c cÃ i Ä‘áº·t.")
    print("Vui lÃ²ng cháº¡y: pip install 'mcp[cli]'")
    exit(1)

# Import memory system
from database import get_memory_manager

# Khá»Ÿi táº¡o MCP server
mcp = FastMCP("AI-Assistant-V2-Memory")

# Base paths
BASE_DIR = Path(__file__).parent.parent.parent
LOCAL_DATA_DIR = BASE_DIR / "local_data"
RESOURCES_DIR = BASE_DIR / "resources"
LOGS_DIR = RESOURCES_DIR / "logs"

# Initialize Memory Manager
memory = get_memory_manager(
    db_path=RESOURCES_DIR / "memory" / "mcp_memory.db"
)

# Auto-create session on startup
SESSION_ID = memory.create_session(project_name="AI-Assistant")
logger.info(f"ğŸš€ Session created: {SESSION_ID}")


# ==================== DECORATOR: Auto-save to memory ====================

def with_memory(importance: int = 5, observation_type: str = "general"):
    """
    Decorator tá»± Ä‘á»™ng lÆ°u tool usage vÃ o memory
    
    Args:
        importance: 1-10 scale
        observation_type: decision, bugfix, feature, refactor, discovery
    """
    def decorator(func):
        def wrapper(*args, **kwargs):
            start_time = time.time()
            success = True
            error_msg = None
            result = None
            
            try:
                # Execute tool
                result = func(*args, **kwargs)
                
                # Log to memory
                duration_ms = int((time.time() - start_time) * 1000)
                memory.log_tool_usage(
                    tool_name=func.__name__,
                    input_params=kwargs,
                    output_data=result,
                    duration_ms=duration_ms,
                    success=True
                )
                
                # Create simple observation
                observation = f"Tool '{func.__name__}' executed successfully"
                if kwargs:
                    param_str = ", ".join([f"{k}={v}" for k, v in list(kwargs.items())[:3]])
                    observation += f" with params: {param_str}"
                
                memory.save_observation(
                    tool_name=func.__name__,
                    observation=observation,
                    observation_type=observation_type,
                    importance=importance,
                    tool_input=kwargs,
                    tool_output=str(result)[:500] if result else None
                )
                
                return result
                
            except Exception as e:
                success = False
                error_msg = str(e)
                
                # Log error to memory
                memory.log_tool_usage(
                    tool_name=func.__name__,
                    input_params=kwargs,
                    output_data=None,
                    duration_ms=int((time.time() - start_time) * 1000),
                    success=False,
                    error_message=error_msg
                )
                
                raise
        
        return wrapper
    return decorator


# ==================== TOOLS: FILE OPERATIONS ====================

@mcp.tool()
@with_memory(importance=5, observation_type="search")
def search_files(query: str, file_type: str = "all", max_results: int = 10) -> Dict[str, Any]:
    """
    TÃ¬m kiáº¿m files trong workspace theo query.
    
    Args:
        query: Tá»« khÃ³a tÃ¬m kiáº¿m
        file_type: Loáº¡i file (all, py, md, json, txt, js, html, css)
        max_results: Sá»‘ káº¿t quáº£ tá»‘i Ä‘a
        
    Returns:
        Dict chá»©a danh sÃ¡ch files tÃ¬m tháº¥y
    """
    results = []
    search_path = BASE_DIR
    
    # Map file types
    extensions = {
        "py": [".py"],
        "md": [".md"],
        "json": [".json"],
        "txt": [".txt"],
        "js": [".js", ".jsx", ".ts", ".tsx"],
        "html": [".html", ".htm"],
        "css": [".css", ".scss", ".sass"],
        "all": None
    }
    
    target_exts = extensions.get(file_type, None)
    
    for file_path in search_path.rglob("*"):
        if len(results) >= max_results:
            break
            
        if not file_path.is_file():
            continue
        
        # Skip certain directories
        if any(skip in str(file_path) for skip in ['.venv', '__pycache__', 'node_modules', '.git']):
            continue
        
        # Check extension
        if target_exts and file_path.suffix not in target_exts:
            continue
        
        # Check query in filename or path
        if query.lower() in str(file_path).lower():
            results.append({
                "path": str(file_path.relative_to(BASE_DIR)),
                "name": file_path.name,
                "size": file_path.stat().st_size,
                "modified": datetime.fromtimestamp(file_path.stat().st_mtime).isoformat()
            })
    
    return {
        "query": query,
        "file_type": file_type,
        "found": len(results),
        "results": results
    }


@mcp.tool()
@with_memory(importance=6, observation_type="read")
def read_file_content(
    file_path: str, 
    start_line: int = 1, 
    end_line: Optional[int] = None,
    max_lines: int = 500
) -> Dict[str, Any]:
    """
    Äá»c ná»™i dung file.
    
    Args:
        file_path: ÄÆ°á»ng dáº«n file (relative to BASE_DIR)
        start_line: DÃ²ng báº¯t Ä‘áº§u (1-based)
        end_line: DÃ²ng káº¿t thÃºc (None = Ä‘áº¿n cuá»‘i file)
        max_lines: Sá»‘ dÃ²ng tá»‘i Ä‘a
        
    Returns:
        Dict chá»©a ná»™i dung file
    """
    full_path = BASE_DIR / file_path
    
    if not full_path.exists():
        return {"error": f"File not found: {file_path}"}
    
    if not full_path.is_file():
        return {"error": f"Not a file: {file_path}"}
    
    try:
        with open(full_path, 'r', encoding='utf-8', errors='ignore') as f:
            lines = f.readlines()
        
        total_lines = len(lines)
        
        # Adjust indices (1-based to 0-based)
        start_idx = max(0, start_line - 1)
        end_idx = min(total_lines, end_line if end_line else total_lines)
        
        # Apply max_lines limit
        if end_idx - start_idx > max_lines:
            end_idx = start_idx + max_lines
        
        selected_lines = lines[start_idx:end_idx]
        
        return {
            "file": file_path,
            "total_lines": total_lines,
            "start_line": start_line,
            "end_line": start_idx + len(selected_lines),
            "lines_returned": len(selected_lines),
            "content": "".join(selected_lines)
        }
        
    except Exception as e:
        return {"error": str(e)}


@mcp.tool()
@with_memory(importance=4, observation_type="list")
def list_directory(directory_path: str = ".", show_hidden: bool = False) -> Dict[str, Any]:
    """
    Liá»‡t kÃª files vÃ  folders trong directory.
    
    Args:
        directory_path: ÄÆ°á»ng dáº«n directory (relative to BASE_DIR)
        show_hidden: Hiá»ƒn thá»‹ files/folders áº©n
        
    Returns:
        Dict chá»©a danh sÃ¡ch files vÃ  folders
    """
    full_path = BASE_DIR / directory_path
    
    if not full_path.exists():
        return {"error": f"Directory not found: {directory_path}"}
    
    if not full_path.is_dir():
        return {"error": f"Not a directory: {directory_path}"}
    
    files = []
    folders = []
    
    for item in full_path.iterdir():
        if not show_hidden and item.name.startswith('.'):
            continue
        
        item_info = {
            "name": item.name,
            "modified": datetime.fromtimestamp(item.stat().st_mtime).isoformat()
        }
        
        if item.is_file():
            item_info["size"] = item.stat().st_size
            files.append(item_info)
        else:
            folders.append(item_info)
    
    return {
        "path": directory_path,
        "folders": sorted(folders, key=lambda x: x['name']),
        "files": sorted(files, key=lambda x: x['name']),
        "total_items": len(files) + len(folders)
    }


# ==================== TOOLS: PROJECT INFO ====================

@mcp.tool()
@with_memory(importance=7, observation_type="info")
def get_project_info() -> Dict[str, Any]:
    """
    Láº¥y thÃ´ng tin tá»•ng quan vá» AI-Assistant project.
    
    Returns:
        Dict chá»©a thÃ´ng tin project
    """
    services = [
        {"name": "Hub Gateway", "port": 3000, "path": "services/hub-gateway"},
        {"name": "ChatBot", "port": 5001, "path": "services/chatbot"},
        {"name": "Text2SQL", "port": 5002, "path": "services/text2sql"},
        {"name": "Document Intelligence", "port": 5003, "path": "services/document-intelligence"},
        {"name": "Speech2Text", "port": 7860, "path": "services/speech2text"},
        {"name": "Stable Diffusion", "port": 7861, "path": "services/stable-diffusion"},
        {"name": "LoRA Training", "port": 7862, "path": "services/lora-training"},
        {"name": "Image Upscale", "port": 7863, "path": "services/image-upscale"},
        {"name": "MCP Server", "port": None, "path": "services/mcp-server"}
    ]
    
    return {
        "project": "AI-Assistant",
        "version": "2.3",
        "services": services,
        "base_directory": str(BASE_DIR),
        "python_version": "3.10.6"
    }


@mcp.tool()
@with_memory(importance=6, observation_type="search")
def search_logs(
    service_name: str, 
    level: str = "ALL", 
    max_lines: int = 100
) -> Dict[str, Any]:
    """
    TÃ¬m kiáº¿m trong log files cá»§a services.
    
    Args:
        service_name: TÃªn service (chatbot, text2sql, hub-gateway, etc.)
        level: Log level (ALL, ERROR, WARNING, INFO, DEBUG)
        max_lines: Sá»‘ dÃ²ng tá»‘i Ä‘a
        
    Returns:
        Dict chá»©a káº¿t quáº£ tÃ¬m kiáº¿m logs
    """
    log_file = LOGS_DIR / f"{service_name}.log"
    
    if not log_file.exists():
        return {
            "service": service_name,
            "error": f"Log file not found: {log_file}"
        }
    
    try:
        with open(log_file, 'r', encoding='utf-8', errors='ignore') as f:
            lines = f.readlines()
        
        # Filter by level
        if level != "ALL":
            filtered = [line for line in lines if level in line]
        else:
            filtered = lines
        
        # Get last N lines
        results = filtered[-max_lines:] if len(filtered) > max_lines else filtered
        
        return {
            "service": service_name,
            "level": level,
            "total_lines": len(lines),
            "filtered_lines": len(filtered),
            "returned_lines": len(results),
            "logs": "".join(results)
        }
        
    except Exception as e:
        return {"error": str(e)}


@mcp.tool()
@with_memory(importance=3, observation_type="calculation")
def calculate(expression: str) -> Dict[str, Any]:
    """
    Thá»±c hiá»‡n tÃ­nh toÃ¡n an toÃ n.
    
    Args:
        expression: Biá»ƒu thá»©c toÃ¡n há»c (vd: "2 + 2", "(10 * 5) / 2")
        
    Returns:
        Dict chá»©a káº¿t quáº£ tÃ­nh toÃ¡n
    """
    try:
        # Safe eval - only allow math operations
        allowed_names = {
            "abs": abs, "round": round, "min": min, "max": max,
            "sum": sum, "pow": pow
        }
        
        result = eval(expression, {"__builtins__": {}}, allowed_names)
        
        return {
            "expression": expression,
            "result": result,
            "type": type(result).__name__
        }
        
    except Exception as e:
        return {
            "expression": expression,
            "error": str(e)
        }


# ==================== TOOLS: MEMORY SYSTEM (NEW!) ====================

@mcp.tool()
def search_memory(
    query: str, 
    limit: int = 10,
    min_importance: int = 0
) -> Dict[str, Any]:
    """
    ğŸ†• TÃ¬m kiáº¿m trong memory (observations tá»« cÃ¡c sessions trÆ°á»›c).
    
    Args:
        query: Tá»« khÃ³a tÃ¬m kiáº¿m
        limit: Sá»‘ káº¿t quáº£ tá»‘i Ä‘a
        min_importance: Äá»™ quan trá»ng tá»‘i thiá»ƒu (0-10)
        
    Returns:
        Dict chá»©a observations tÃ¬m tháº¥y
    """
    results = memory.search_observations(
        query=query,
        limit=limit,
        min_importance=min_importance
    )
    
    return {
        "query": query,
        "found": len(results),
        "observations": [
            {
                "id": obs['id'],
                "observation": obs['observation'],
                "type": obs['observation_type'],
                "importance": obs['importance'],
                "tool": obs['tool_name'],
                "timestamp": obs['timestamp'],
                "files": json.loads(obs['file_references']) if obs['file_references'] else [],
                "tags": json.loads(obs['concept_tags']) if obs['concept_tags'] else []
            }
            for obs in results
        ]
    }


@mcp.tool()
def get_recent_context(limit: int = 30, min_importance: int = 5) -> Dict[str, Any]:
    """
    ğŸ†• Láº¥y context gáº§n Ä‘Ã¢y Ä‘á»ƒ inject vÃ o session má»›i.
    
    Args:
        limit: Sá»‘ observations
        min_importance: Äá»™ quan trá»ng tá»‘i thiá»ƒu
        
    Returns:
        Dict chá»©a formatted context
    """
    context_text = memory.get_context_for_session(
        max_observations=limit,
        min_importance=min_importance
    )
    
    observations = memory.get_recent_observations(
        limit=limit,
        min_importance=min_importance
    )
    
    return {
        "context": context_text,
        "observation_count": len(observations),
        "min_importance": min_importance
    }


@mcp.tool()
def get_memory_by_file(file_path: str, limit: int = 20) -> Dict[str, Any]:
    """
    ğŸ†• Láº¥y memories liÃªn quan Ä‘áº¿n file cá»¥ thá»ƒ.
    
    Args:
        file_path: ÄÆ°á»ng dáº«n file
        limit: Sá»‘ káº¿t quáº£
        
    Returns:
        Dict chá»©a observations liÃªn quan
    """
    results = memory.get_observations_by_file(file_path, limit)
    
    return {
        "file": file_path,
        "found": len(results),
        "observations": [
            {
                "observation": obs['observation'],
                "type": obs['observation_type'],
                "importance": obs['importance'],
                "timestamp": obs['timestamp']
            }
            for obs in results
        ]
    }


@mcp.tool()
def get_session_history(limit: int = 10) -> Dict[str, Any]:
    """
    ğŸ†• Láº¥y lá»‹ch sá»­ cÃ¡c sessions gáº§n Ä‘Ã¢y.
    
    Args:
        limit: Sá»‘ sessions
        
    Returns:
        Dict chá»©a session history
    """
    sessions = memory.get_recent_sessions(limit)
    
    return {
        "total_sessions": len(sessions),
        "sessions": [
            {
                "id": sess['id'],
                "project": sess['project_name'],
                "start_time": sess['start_time'],
                "tool_count": sess['tool_count'],
                "summary": sess['summary'],
                "observation_count": sess['observation_count']
            }
            for sess in sessions
        ]
    }


@mcp.tool()
def save_important_observation(
    observation: str,
    observation_type: str = "general",
    importance: int = 8,
    file_references: Optional[List[str]] = None,
    tags: Optional[List[str]] = None
) -> Dict[str, Any]:
    """
    ğŸ†• LÆ°u má»™t observation quan trá»ng thá»§ cÃ´ng.
    
    Args:
        observation: Ná»™i dung observation
        observation_type: decision, bugfix, feature, refactor, discovery
        importance: 1-10 scale
        file_references: Danh sÃ¡ch files liÃªn quan
        tags: Tags (discovery, problem-solution, pattern, etc.)
        
    Returns:
        Dict vá»›i observation_id
    """
    obs_id = memory.save_observation(
        tool_name="manual_save",
        observation=observation,
        observation_type=observation_type,
        concept_tags=tags,
        file_references=file_references,
        importance=importance
    )
    
    return {
        "saved": True,
        "observation_id": obs_id,
        "importance": importance,
        "type": observation_type
    }


@mcp.tool()
def get_memory_statistics() -> Dict[str, Any]:
    """
    ğŸ†• Láº¥y thá»‘ng kÃª vá» memory system.
    
    Returns:
        Dict chá»©a statistics
    """
    stats = memory.get_statistics()
    
    return {
        "total_sessions": stats['total_sessions'],
        "total_observations": stats['total_observations'],
        "total_tools_used": stats['total_tools'],
        "total_tokens": stats['total_tokens'],
        "top_tools": stats['tool_stats'][:5]
    }


# ==================== RESOURCES ====================

@mcp.resource("config://model")
def get_model_config() -> str:
    """Cáº¥u hÃ¬nh models cá»§a AI-Assistant"""
    config_file = BASE_DIR / "config" / "model_config.py"
    if config_file.exists():
        with open(config_file, 'r', encoding='utf-8') as f:
            return f.read()
    return "Model config not found"


@mcp.resource("config://logging")
def get_logging_config() -> str:
    """Cáº¥u hÃ¬nh logging cá»§a AI-Assistant"""
    config_file = BASE_DIR / "config" / "logging_config.py"
    if config_file.exists():
        with open(config_file, 'r', encoding='utf-8') as f:
            return f.read()
    return "Logging config not found"


@mcp.resource("docs://readme")
def get_readme() -> str:
    """README cá»§a AI-Assistant project"""
    readme_file = BASE_DIR / "README.md"
    if readme_file.exists():
        with open(readme_file, 'r', encoding='utf-8') as f:
            return f.read()
    return "README not found"


@mcp.resource("docs://structure")
def get_project_structure() -> str:
    """Cáº¥u trÃºc thÆ° má»¥c cá»§a AI-Assistant"""
    structure_file = BASE_DIR / "docs" / "STRUCTURE.md"
    if structure_file.exists():
        with open(structure_file, 'r', encoding='utf-8') as f:
            return f.read()
    return "Structure documentation not found"


@mcp.resource("memory://context")
def get_memory_context_resource() -> str:
    """ğŸ†• Context tá»« memory Ä‘á»ƒ inject vÃ o session"""
    return memory.get_context_for_session(max_observations=30, min_importance=5)


# ==================== PROMPTS ====================

@mcp.prompt()
def code_review(file_path: str) -> str:
    """
    Prompt template Ä‘á»ƒ review code.
    
    Args:
        file_path: ÄÆ°á»ng dáº«n file cáº§n review
    """
    return f"""HÃ£y review code trong file: {file_path}

Vui lÃ²ng phÃ¢n tÃ­ch:
1. Code quality vÃ  best practices
2. Potential bugs hoáº·c security issues
3. Performance concerns
4. Suggestions for improvement

Sá»­ dá»¥ng tool read_file_content Ä‘á»ƒ Ä‘á»c file vÃ  phÃ¢n tÃ­ch chi tiáº¿t."""


@mcp.prompt()
def debug_error(error_message: str, service_name: str) -> str:
    """
    Prompt template Ä‘á»ƒ debug lá»—i.
    
    Args:
        error_message: ThÃ´ng bÃ¡o lá»—i
        service_name: TÃªn service bá»‹ lá»—i
    """
    return f"""Service '{service_name}' Ä‘ang gáº·p lá»—i:
Error: {error_message}

HÃ£y giÃºp tÃ´i debug báº±ng cÃ¡ch:
1. TÃ¬m kiáº¿m logs liÃªn quan (search_logs)
2. Kiá»ƒm tra memory xem cÃ³ gáº·p lá»—i tÆ°Æ¡ng tá»± trÆ°á»›c Ä‘Ã¢y khÃ´ng (search_memory)
3. XÃ¡c Ä‘á»‹nh root cause
4. Äá» xuáº¥t solution"""


@mcp.prompt()
def explain_code(file_path: str, function_name: Optional[str] = None) -> str:
    """
    Prompt template Ä‘á»ƒ giáº£i thÃ­ch code.
    
    Args:
        file_path: ÄÆ°á»ng dáº«n file
        function_name: TÃªn function cáº§n giáº£i thÃ­ch (optional)
    """
    target = f"function {function_name} trong " if function_name else ""
    return f"""HÃ£y giáº£i thÃ­ch code {target}file: {file_path}

Vui lÃ²ng:
1. Äá»c code (read_file_content)
2. Kiá»ƒm tra memory xem cÃ³ context vá» file nÃ y khÃ´ng (get_memory_by_file)
3. Giáº£i thÃ­ch logic báº±ng tiáº¿ng Viá»‡t
4. Input/Output expected
5. CÃ¡c edge cases cáº§n lÆ°u Ã½"""


@mcp.prompt()
def session_summary() -> str:
    """ğŸ†• Prompt Ä‘á»ƒ táº¡o summary cho session"""
    return """HÃ£y táº¡o summary cho session lÃ m viá»‡c vá»«a rá»“i.

Sá»­ dá»¥ng:
1. get_session_history Ä‘á»ƒ xem session hiá»‡n táº¡i
2. get_memory_statistics Ä‘á»ƒ xem cÃ¡c tools Ä‘Ã£ dÃ¹ng
3. Tá»•ng há»£p thÃ nh summary ngáº¯n gá»n vá»›i:
   - CÃ¡c cÃ´ng viá»‡c Ä‘Ã£ lÃ m
   - Files Ä‘Ã£ thao tÃ¡c
   - Decisions quan trá»ng
   - Next steps"""


# ==================== MAIN ====================

def main():
    """Khá»Ÿi Ä‘á»™ng MCP server"""
    print(f"ğŸš€ Starting AI-Assistant MCP Server V2.0 WITH MEMORY...")
    print(f"ğŸ“ Base Directory: {BASE_DIR}")
    print(f"ğŸ§  Memory Database: {memory.db_path}")
    print(f"ğŸ“‹ Session ID: {SESSION_ID}")
    print(f"\nâœ¨ NEW FEATURES:")
    print(f"   ğŸ”§ Tools: All original tools + 6 memory tools")
    print(f"   ğŸ“¦ Resources: Config, docs + memory context")
    print(f"   ğŸ’¬ Prompts: Code review, debug, explain + session summary")
    print(f"   ğŸ§  MEMORY: Persistent storage, search history, AI observations")
    print(f"\nâœ… Server is ready!")
    print(f"ğŸ“¡ Listening for MCP client connections...")
    print(f"\nğŸ’¡ TIP: Sau má»—i session, memory sáº½ tá»± Ä‘á»™ng lÆ°u láº¡i!")
    
    try:
        # Run server
        mcp.run()
    finally:
        # End session on shutdown
        print(f"\n\nğŸ›‘ Shutting down...")
        print(f"ğŸ’¾ Saving session summary...")
        memory.end_session(SESSION_ID, summary="Session ended")
        print(f"âœ… Session saved: {SESSION_ID}")


if __name__ == "__main__":
    main()
