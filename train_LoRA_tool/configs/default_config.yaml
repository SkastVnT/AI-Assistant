# LoRA Training Configuration
# For image datasets with 500-2000 images

# Model Configuration
model:
  pretrained_model_name_or_path: "runwayml/stable-diffusion-v1-5"  # or "stabilityai/stable-diffusion-2-1"
  revision: null  # specific model revision (optional)

# LoRA Configuration
lora:
  rank: 16  # LoRA rank (4, 8, 16, 32, 64, 128)
  alpha: 32  # LoRA alpha (typically 2x rank)
  dropout: 0.0  # LoRA dropout rate
  target_modules:  # Which modules to apply LoRA to
    - "to_q"
    - "to_k"
    - "to_v"
    - "to_out.0"
    - "ff.net.0.proj"
    - "ff.net.2"

# Dataset Configuration
dataset:
  train_data_dir: "data/train"  # Directory containing training images
  val_data_dir: null  # Optional validation directory
  resolution: 512  # Image resolution (512 for SD1.5, 768 for SD2.1, 1024 for SDXL)
  center_crop: true  # Center crop images
  random_flip: true  # Random horizontal flip for augmentation
  caption_extension: ".txt"  # Caption file extension (.txt, .caption, .tags)
  
  # Advanced features (NEW v2.2)
  use_buckets: true  # Multi-resolution training (buckets)
  bucket_sizes:  # Resolution buckets (auto-generated if empty)
    - [512, 512]
    - [768, 512]
    - [512, 768]
    - [640, 640]
    - [896, 512]
    - [512, 896]
  
  # Caption processing
  shuffle_caption: true  # Shuffle caption tags (for booru-style tags)
  keep_tokens: 1  # Number of tokens to keep at start (e.g., "1girl")
  
  # Latent caching (faster training, more VRAM)
  cache_latents: true  # Cache VAE latents to disk
  cache_latents_to_disk: false  # Store latents on disk vs RAM

# Training Configuration
training:
  # Basic settings
  num_train_epochs: 10  # Number of training epochs
  train_batch_size: 1  # Batch size per GPU
  gradient_accumulation_steps: 4  # Accumulate gradients over N steps
  
  # Optimizer settings
  optimizer: "prodigy"  # Optimizer type (adamw, adam, prodigy, adafactor)
  learning_rate: 1.0  # Learning rate (1.0 for Prodigy, 1e-4 for AdamW)
  weight_decay: 0.01  # Weight decay
  adam_beta1: 0.9
  adam_beta2: 0.999
  adam_epsilon: 1.0e-8
  max_grad_norm: 1.0  # Gradient clipping
  
  # Learning rate scheduler
  lr_scheduler: "cosine_with_restarts"  # Scheduler type (constant, linear, cosine, cosine_with_restarts)
  lr_warmup_steps: 100  # Number of warmup steps
  
  # Advanced training features (NEW v2.2)
  use_ema: true  # Use Exponential Moving Average for model weights
  ema_decay: 0.9999  # EMA decay rate (0.999-0.9999)
  
  min_snr_gamma: 5.0  # Min-SNR weighting (improves quality, recommended: 5.0)
  noise_offset: 0.1  # Noise offset for darker/lighter images (0.0-0.2)
  use_pyramid_noise: false  # Multi-scale pyramid noise (slower but better)
  
  adaptive_loss_weight: true  # Adaptive loss weighting
  train_text_encoder: false  # Also train text encoder (higher VRAM)
  
  # LoRA+ (NEW v2.3) - 2-3x faster convergence
  use_loraplus: true  # Enable LoRA+ technique
  loraplus_lr_ratio: 16.0  # Global LR ratio for B layers (paper recommends 16)
  loraplus_unet_lr_ratio: null  # Specific ratio for UNet (overrides global if set)
  loraplus_text_encoder_lr_ratio: null  # Specific ratio for Text Encoder
  
  # Scheduled Huber Loss (NEW v2.3) - robust against outliers
  loss_type: "smooth_l1"  # Loss type: 'l2' (MSE), 'huber', 'smooth_l1'
  huber_c: 0.1  # Huber parameter (delta/beta)
  huber_schedule: "snr"  # Scheduling: 'snr' (recommended), 'exponential', 'constant'
  
  # Training steps
  max_train_steps: null  # Override epochs with max steps (optional)
  
  # Validation and saving
  validation_epochs: 1  # Run validation every N epochs
  save_steps: 2  # Save checkpoint every N epochs
  save_model_epochs: 5  # Save full model every N epochs
  
  # Output directories
  output_dir: "outputs/lora_models"
  checkpoint_dir: "outputs/checkpoints"
  
  # DataLoader settings
  dataloader_num_workers: 4  # Number of data loading workers
  
  # Mixed precision training
  mixed_precision: "fp16"  # fp16, bf16, or no
  
  # Gradient checkpointing (save memory)
  gradient_checkpointing: true
  
  # Prior preservation (optional, for dreambooth-style training)
  with_prior_preservation: false
  prior_loss_weight: 1.0
  num_class_images: 100
  class_data_dir: null
  class_prompt: null

# Logging Configuration
logging:
  log_dir: "outputs/logs"
  logging_steps: 10  # Log every N steps
  
  # Wandb/Tensorboard (optional)
  use_wandb: false
  wandb_project: "lora-training"
  wandb_run_name: null
  
  use_tensorboard: false
  tensorboard_dir: "outputs/tensorboard"
  
  # Sample generation during training
  generate_samples: true
  sample_steps: 100  # Generate samples every N steps
  num_samples: 4  # Number of samples to generate
  sample_prompts:
    - "a photo of the subject"
    - "the subject in a park"
    - "close-up portrait of the subject"
    - "the subject wearing sunglasses"

# Advanced Settings
advanced:
  # Noise offset (improves contrast)
  noise_offset: 0.0
  
  # SNR gamma (from paper "Min-SNR-Î³")
  snr_gamma: null
  
  # EMA (Exponential Moving Average)
  use_ema: false
  ema_decay: 0.999
  
  # XFormers memory efficient attention
  enable_xformers: true
  
  # Text encoder training
  train_text_encoder: false
  text_encoder_lr: 5.0e-6
  
  # Color jitter augmentation
  color_jitter: false
  
  # Random rotation augmentation
  random_rotation: false
  
  # Cache latents (faster but uses more disk space)
  cache_latents: false
